# Models Management - 快速开始指南
## 5 分钟上手 AI 模型管理

---

## 🚀 快速开始

### 第一步: 启动服务 (1 分钟)

```bash
# 1. 确保 Ollama 正在运行
curl http://localhost:11434/api/version
# 应该返回: {"version":"0.15.2"}

# 如果没有运行，启动 Ollama
ollama serve &

# 2. 启动 AgentOS WebUI
cd /Users/pangge/PycharmProjects/AgentOS
agentos webui

# 3. 打开浏览器
open http://localhost:8000
```

---

### 第二步: 访问 Models 页面 (10 秒)

1. 打开浏览器访问 http://localhost:8000
2. 点击左侧导航栏 **Settings** (设置)
3. 点击 **Models** (模型管理)

✅ 你应该看到 Models 管理页面

---

### 第三步: 下载你的第一个模型 (5-15 分钟)

#### 推荐模型 (首次使用)

🎯 **llama3.2:1b** - 最快的测试模型
- **大小:** 1.3 GB
- **下载时间:** 5-10 分钟 (取决于网速)
- **特点:** 轻量级、快速响应
- **适合:** 快速测试、日常对话

#### 下载步骤

1. **点击 [+ Download Model] 按钮**
   - 位置: 页面右上角

2. **选择推荐模型**
   - 点击 "Llama 3.2 (1B)" 卡片
   - 卡片会高亮显示

3. **开始下载**
   - 点击 [Download] 按钮
   - 对话框关闭

4. **观察进度**
   - 进度条出现在页面中部
   - 实时显示下载进度 (0% → 100%)
   - 显示当前步骤 (拉取清单、下载、验证)

5. **等待完成**
   - 进度达到 100%
   - 显示 "✓ Download completed successfully!"
   - 模型自动出现在列表中
   - 进度条 2 秒后自动消失

✅ 完成！你的第一个模型已安装

---

## 📚 功能说明

### 1️⃣ 服务状态监控

**位置:** 页面顶部

**显示内容:**
- **Ollama 状态**
  - ✓ Available - 绿色 (正常运行)
  - ✗ Not Available - 灰色 (未运行)
  - 版本号 (如: v0.15.2)

- **llama.cpp 状态**
  - ✓ Available - 可用
  - ✗ Not Available - 未安装

**自动刷新:** 每 5 秒更新一次

---

### 2️⃣ 模型列表

**位置:** 页面主体区域

**显示方式:**
- 网格布局 (响应式)
  - 桌面: 3 列
  - 平板: 2 列
  - 手机: 1 列

**模型卡片信息:**
- 🤖 模型图标
- 📝 模型名称 (如: llama3.2:3b)
- 🏷️ Provider (ollama)
- 📊 大小 (如: 2.0 GB)
- 🔢 参数量 (如: 3B)
- 🏷️ 标签 (chat, fast 等)
- 🔘 操作按钮: [Info] [Delete]

**空状态:**
- 如果没有模型，显示友好提示
- [Download Model] 按钮引导下载

---

### 3️⃣ 下载模型

#### 方式一: 推荐模型 (最简单)

1. 点击 [+ Download Model]
2. 从推荐列表选择一个模型
3. 点击 [Download]

**推荐模型列表:**
- **Qwen 2.5 (7B)** - 4.7 GB
  - 中文优化，支持代码生成

- **Llama 3.2 (3B)** - 2.0 GB
  - 快速响应，适合日常对话

- **Llama 3.2 (1B)** - 1.3 GB ⭐
  - 超轻量级，快速响应

- **Gemma 2 (2B)** - 1.6 GB
  - Google 开源模型

- **Qwen 2.5 Coder (7B)** - 4.7 GB
  - 代码生成专用

#### 方式二: 自定义模型名称

1. 点击 [+ Download Model]
2. 在 "Custom Model Name" 输入框输入模型名称
   - 例如: `mistral:7b`
   - 例如: `codellama:13b`
3. 点击 [Download]

**支持的格式:**
- `model_name:tag` (如: llama3.2:3b)
- `model_name:version` (如: qwen2.5:7b)

---

### 4️⃣ 查看模型信息

**操作:** 点击模型卡片上的 [Info] 按钮

**显示信息:**
- **基本信息**
  - 名称
  - Provider
  - Family (如: llama)

- **技术参数**
  - 大小 (GB)
  - 参数量 (B)
  - 量化级别 (如果有)

- **其他信息**
  - 最后修改时间
  - Digest (哈希值)
  - 标签列表

**关闭方式:**
- 点击 [Close] 按钮
- 点击背景区域
- 按 Esc 键

---

### 5️⃣ 删除模型

**操作:** 点击模型卡片上的 [Delete] 按钮

**确认对话框:**
- 显示模型名称
- ⚠️ 警告提示: "此操作不可撤销"
- 黄色警告框

**按钮:**
- [Cancel] - 取消删除
- [Delete] - 确认删除

**删除后:**
- 显示成功通知
- 模型从列表中移除
- 实际从 Ollama 中删除

⚠️ **注意:** 删除操作不可恢复！

---

## 🎯 常见操作

### 下载小型模型 (快速测试)

```
推荐: llama3.2:1b (1.3 GB)
时间: 5-10 分钟
用途: 快速测试、验证功能
```

### 下载中文模型 (中文对话)

```
推荐: qwen2.5:7b (4.7 GB)
时间: 15-30 分钟
特点: 中文优化、支持代码
```

### 下载代码模型 (编程助手)

```
推荐: qwen2.5-coder:7b (4.7 GB)
时间: 15-30 分钟
特点: 代码生成专用
```

### 同时下载多个模型

✅ **支持并发下载**
- 可以同时启动多个下载
- 每个模型独立显示进度条
- 互不干扰

---

## 💡 使用技巧

### 技巧 1: 选择合适的模型大小

| 大小 | 推荐场景 | 示例 |
|------|---------|------|
| 1-2 GB | 快速测试、轻量对话 | llama3.2:1b |
| 2-4 GB | 日常使用、通用对话 | llama3.2:3b |
| 4-8 GB | 专业任务、高质量输出 | qwen2.5:7b |
| 8+ GB | 复杂任务、最佳质量 | llama3.2:13b |

### 技巧 2: 监控下载进度

- 进度条实时更新 (每 500ms)
- 显示当前步骤:
  - "Starting download..." - 初始化
  - "Pulling manifest" - 拉取清单
  - "Downloading: X%" - 下载中
  - "Verifying checksum" - 验证校验和
  - "Download complete" - 完成

### 技巧 3: 处理下载失败

**如果下载失败:**
1. 查看错误信息 (红色文本)
2. 常见原因:
   - 网络连接问题
   - 模型名称错误
   - 磁盘空间不足
3. 解决后重新下载

### 技巧 4: 管理磁盘空间

**检查模型大小:**
- 查看模型卡片上的 "Size" 字段
- 下载前确保有足够空间

**删除不需要的模型:**
- 定期清理不用的模型
- 释放磁盘空间

---

## 🔧 故障排除

### 问题 1: Ollama 状态显示 "Not Available"

**解决方案:**
```bash
# 检查 Ollama 是否运行
ps aux | grep ollama

# 如果没有运行，启动 Ollama
ollama serve &

# 验证
curl http://localhost:11434/api/version
```

### 问题 2: 模型列表为空

**可能原因:**
- Ollama 未运行
- 还没有安装模型

**解决方案:**
1. 确保 Ollama 运行中
2. 下载你的第一个模型

### 问题 3: 下载一直卡在 0%

**可能原因:**
- 网络连接问题
- Ollama 服务问题

**解决方案:**
```bash
# 检查网络连接
ping ollama.com

# 检查 Ollama 日志
tail -f ~/.ollama/logs/server.log

# 重启 Ollama
pkill ollama
ollama serve &
```

### 问题 4: 页面无法加载

**解决方案:**
```bash
# 检查 WebUI 是否运行
curl http://localhost:8000

# 如果没有运行，启动 WebUI
agentos webui

# 检查端口占用
lsof -i :8000
```

---

## 📊 性能参考

### 下载速度 (参考)

| 网速 | 1.3 GB 模型 | 4.7 GB 模型 |
|------|------------|------------|
| 10 Mbps | ~17 分钟 | ~63 分钟 |
| 50 Mbps | ~3.5 分钟 | ~13 分钟 |
| 100 Mbps | ~2 分钟 | ~6 分钟 |
| 500 Mbps | ~30 秒 | ~2 分钟 |

**注意:** 实际速度取决于:
- 网络带宽
- Ollama 服务器响应
- 本地磁盘写入速度

### 页面性能

- **页面加载:** < 2 秒
- **模型列表刷新:** < 500ms
- **进度更新:** < 1 秒
- **操作响应:** < 300ms

---

## 🎓 进阶使用

### 批量下载脚本

```bash
# 下载多个模型 (命令行方式)
ollama pull llama3.2:1b
ollama pull llama3.2:3b
ollama pull qwen2.5:7b
```

### 查看本地模型

```bash
# 命令行查看
ollama list

# 查看详细信息
ollama show llama3.2:3b
```

### 删除模型 (命令行)

```bash
# 删除指定模型
ollama rm llama3.2:3b

# 确认删除
ollama list
```

---

## 📚 推荐学习路径

### 新手路径 (第一天)

1. ✅ **启动服务** (5 分钟)
   - 启动 Ollama
   - 启动 WebUI

2. ✅ **下载第一个模型** (10 分钟)
   - 选择 llama3.2:1b
   - 观察下载过程

3. ✅ **探索功能** (10 分钟)
   - 查看模型信息
   - 测试删除 (可选)

### 进阶路径 (第一周)

1. ✅ **尝试不同模型**
   - 小型: llama3.2:1b
   - 中型: llama3.2:3b
   - 大型: qwen2.5:7b

2. ✅ **对比性能**
   - 响应速度
   - 输出质量
   - 资源占用

3. ✅ **优化使用**
   - 根据任务选择模型
   - 管理磁盘空间

---

## 🔗 相关资源

### 官方文档
- Ollama 文档: https://ollama.com/docs
- Ollama 模型库: https://ollama.com/library

### AgentOS 文档
- API 文档: `/Users/pangge/PycharmProjects/AgentOS/agentos/webui/api/models.py`
- 测试报告: `MODELS_E2E_TEST_REPORT.md`
- 完整文档: `MODELS_FEATURE_COMPLETION_SUMMARY.md`

### 技术支持
- 测试计划: `MODELS_E2E_TEST_PLAN.md`
- 问题排查: 查看上方 "故障排除" 章节

---

## ✅ 快速检查清单

使用前检查:
- [ ] Ollama 已安装
- [ ] Ollama 服务运行中
- [ ] AgentOS WebUI 已启动
- [ ] 浏览器可访问 http://localhost:8000

首次使用:
- [ ] 访问 Models 页面
- [ ] 查看服务状态
- [ ] 下载测试模型 (llama3.2:1b)
- [ ] 验证模型出现在列表中

日常使用:
- [ ] 检查模型列表
- [ ] 根据需要下载新模型
- [ ] 清理不用的模型
- [ ] 监控磁盘空间

---

## 🎉 总结

**Models Management 功能让 AI 模型管理变得简单:**

✅ **一键下载** - 点击即可开始
✅ **实时进度** - 随时了解下载状态
✅ **信息完整** - 清晰展示模型详情
✅ **操作简单** - 直观的用户界面
✅ **性能优秀** - 快速响应，流畅体验

**现在就开始下载你的第一个 AI 模型吧！** 🚀

---

**需要帮助?**
- 查看测试报告了解更多功能
- 参考故障排除章节解决问题
- 查看完整文档获取详细信息

---

**文档版本:** 1.0
**更新日期:** 2026-01-30
**适用版本:** AgentOS v0.6.0+

---

**END OF QUICK START GUIDE**
