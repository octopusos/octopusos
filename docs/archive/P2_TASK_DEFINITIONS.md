# P2 ä»»åŠ¡å®šä¹‰ï¼šè¯¦ç»†å®æ–½æŒ‡å—

**é¡¹ç›®**: AgentOS P2 - 100åˆ†è·¯å¾„å®æ–½
**ç‰ˆæœ¬**: v1.0
**æ—¥æœŸ**: 2026-01-30

---

## ä»»åŠ¡æ€»è§ˆ

æœ¬æ–‡æ¡£å®šä¹‰P2é˜¶æ®µçš„4ä¸ªå¹¶è¡Œä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«è¯¦ç»†çš„å®æ–½æ­¥éª¤ã€éªŒæ”¶æ ‡å‡†å’Œé¢„æœŸè¾“å‡ºã€‚

| ä»»åŠ¡ID | ä»»åŠ¡åç§° | ä¼˜å…ˆçº§ | å·¥æ—¶ | å¾—åˆ†æå‡ | ROI | å¯å¹¶è¡Œ |
|--------|----------|--------|------|----------|-----|--------|
| **P2-A** | E2Eæµ‹è¯•ç¯å¢ƒä¿®å¤ | P0 | 1.5h | +6åˆ† | 4.0 | - |
| **P2-B** | è¦†ç›–ç‡æå‡è‡³85% | P1 | 3.0h | +2åˆ† | 0.67 | ä¸P2-C |
| **P2-C** | è¿ç»´å›æ”¾å·¥å…· | P1 | 1.0h | +2åˆ† | 2.0 | ä¸P2-B |
| **P2-D** | å®Œæ•´æ€§å†²åˆº100åˆ† | P2 | 2.0h | +1åˆ† | 0.5 | - |

---

## P2-A: E2Eæµ‹è¯•ç¯å¢ƒä¿®å¤

### ä»»åŠ¡å…ƒä¿¡æ¯

- **ä»»åŠ¡ID**: P2-A
- **ä¼˜å…ˆçº§**: P0ï¼ˆæœ€é«˜ï¼‰
- **å‰ç½®ä¾èµ–**: æ— 
- **é¢„ä¼°å·¥æ—¶**: 1.5å°æ—¶
- **å¾—åˆ†æå‡**: +6åˆ†ï¼ˆ89 â†’ 95ï¼‰
- **ç›®æ ‡**: ä¿®å¤E2Eæµ‹è¯•ç¯å¢ƒï¼Œä½¿æ‰€æœ‰E2Eæµ‹è¯•å¯æ­£å¸¸è¿è¡Œ

### å­ä»»åŠ¡æ¸…å•

#### å­ä»»åŠ¡ A1: ä¿®å¤Retry E2Eæ•°æ®åº“åˆå§‹åŒ–

**é—®é¢˜æè¿°**:
- æµ‹è¯•æ–‡ä»¶: `tests/integration/task/test_retry_e2e.py`
- ç—‡çŠ¶: 13/16æµ‹è¯•å¤±è´¥ï¼Œé”™è¯¯`sqlite3.OperationalError: no such table: tasks`
- æ ¹å› : æµ‹è¯•fixtureæœªæ­£ç¡®åˆå§‹åŒ–æ•°æ®åº“schema

**å®æ–½æ­¥éª¤**:

1. **ç¼–è¾‘æµ‹è¯•æ–‡ä»¶** (15åˆ†é’Ÿ)
   ```bash
   # ç¼–è¾‘æ–‡ä»¶
   vim tests/integration/task/test_retry_e2e.py
   ```

2. **æ·»åŠ æ•°æ®åº“åˆå§‹åŒ–fixture** (30åˆ†é’Ÿ)
   ```python
   import sqlite3
   import os
   from pathlib import Path

   @pytest.fixture(autouse=True)
   def setup_retry_test_db(tmp_path):
       """Initialize test database with complete schema for retry tests"""
       db_path = tmp_path / "retry_test.db"
       conn = sqlite3.connect(str(db_path))
       conn.row_factory = sqlite3.Row

       # åŠ è½½å®Œæ•´schema
       schema_path = Path(__file__).parent.parent.parent.parent / \
                     "agentos/store/migrations/schema_v31_project_aware.sql"

       with open(schema_path) as f:
           schema_sql = f.read()
           # è¿‡æ»¤ç¤ºä¾‹SQL blockï¼ˆå‚è€ƒtest_event_service.pyçš„åšæ³•ï¼‰
           lines = []
           in_example = False
           for line in schema_sql.split('\n'):
               if '-- Example:' in line:
                   in_example = True
               elif in_example and line.strip().startswith('--'):
                   in_example = False
               elif not in_example:
                   lines.append(line)

           conn.executescript('\n'.join(lines))

       conn.close()

       # è®¾ç½®ç¯å¢ƒå˜é‡æŒ‡å‘æµ‹è¯•æ•°æ®åº“
       os.environ["AGENTOS_DB_PATH"] = str(db_path)
       yield db_path

       # æ¸…ç†
       if "AGENTOS_DB_PATH" in os.environ:
           del os.environ["AGENTOS_DB_PATH"]
   ```

3. **éªŒè¯ä¿®å¤** (15åˆ†é’Ÿ)
   ```bash
   # è¿è¡ŒRetry E2Eæµ‹è¯•
   pytest tests/integration/task/test_retry_e2e.py -v --tb=short

   # é¢„æœŸç»“æœ: 16/16 passed (100%)
   ```

**é¢„æœŸè¾“å‡º**:
- ä¿®æ”¹æ–‡ä»¶: `tests/integration/task/test_retry_e2e.py`
- æµ‹è¯•é€šè¿‡: 16/16 (100%)
- å¾—åˆ†æå‡: +4åˆ†

---

#### å­ä»»åŠ¡ A2: ä¿®å¤Timeout exit_reason

**é—®é¢˜æè¿°**:
- æµ‹è¯•æ–‡ä»¶: `tests/integration/task/test_timeout_e2e.py`
- æµ‹è¯•ç”¨ä¾‹: `test_task_timeout_after_limit`
- ç—‡çŠ¶: exit_reason='unknown'è€Œé'timeout'
- æ ¹å› : runneræœªåœ¨è¶…æ—¶æ—¶æ­£ç¡®è®¾ç½®exit_reason

**å®æ–½æ­¥éª¤**:

1. **å®šä½è¶…æ—¶å¤„ç†ä»£ç ** (10åˆ†é’Ÿ)
   ```bash
   # æŸ¥æ‰¾è¶…æ—¶å¤„ç†é€»è¾‘
   grep -rn "is_timeout" agentos/core/runner/
   grep -rn "timeout_manager" agentos/core/runner/
   ```

2. **ä¿®æ”¹task_runner.py** (15åˆ†é’Ÿ)
   ```python
   # æ–‡ä»¶: agentos/core/runner/task_runner.py
   # å®šä½åˆ°è¶…æ—¶æ£€æŸ¥é€»è¾‘ï¼ˆå¤§çº¦ç¬¬200-250è¡Œï¼‰

   # åœ¨è¶…æ—¶æ£€æµ‹åæ·»åŠ metadataè®¾ç½®
   if is_timeout:
       # 1. é¦–å…ˆæ›´æ–°ä»»åŠ¡metadata
       task_manager.update_task_metadata(
           task_id=task.task_id,
           metadata={"exit_reason": "timeout"}
       )

       # 2. ç„¶åæ‰§è¡ŒçŠ¶æ€è½¬æ¢
       state_machine.transition(
           task_id=task.task_id,
           to="failed",
           actor="timeout_manager",
           reason=timeout_message,
           metadata={"exit_reason": "timeout"}  # ç¡®ä¿metadataä¼ é€’
       )

       # 3. è®°å½•å®¡è®¡æ—¥å¿—
       audit_service.record_event(
           task_id=task.task_id,
           event_type="TASK_TIMEOUT",
           level="ERROR",
           payload={
               "timeout_seconds": timeout_config.get("timeout_seconds"),
               "elapsed_seconds": elapsed_seconds,
               "exit_reason": "timeout"
           }
       )
   ```

3. **éªŒè¯ä¿®å¤** (5åˆ†é’Ÿ)
   ```bash
   # è¿è¡Œå•ä¸ªæµ‹è¯•
   pytest tests/integration/task/test_timeout_e2e.py::test_task_timeout_after_limit -v

   # é¢„æœŸç»“æœ: PASSED

   # è¿è¡Œå®Œæ•´Timeout E2Eå¥—ä»¶
   pytest tests/integration/task/test_timeout_e2e.py -v

   # é¢„æœŸç»“æœ: 5/5 passed (100%)
   ```

**é¢„æœŸè¾“å‡º**:
- ä¿®æ”¹æ–‡ä»¶: `agentos/core/runner/task_runner.py`
- æµ‹è¯•é€šè¿‡: 5/5 (100%)
- å¾—åˆ†æå‡: +1åˆ†

---

#### å­ä»»åŠ¡ A3: éªŒè¯å®Œæ•´E2Eå¥—ä»¶

**å®æ–½æ­¥éª¤**:

1. **è¿è¡Œå®Œæ•´E2Eæµ‹è¯•å¥—ä»¶** (10åˆ†é’Ÿ)
   ```bash
   # è¿è¡Œæ‰€æœ‰E2Eæµ‹è¯•
   pytest tests/integration/task/ -v --tb=short

   # é¢„æœŸç»“æœ:
   # - test_retry_e2e.py: 16/16 passed âœ…
   # - test_timeout_e2e.py: 5/5 passed âœ…
   # - test_cancel_running_e2e.py: 7/7 passed âœ…
   # - æ€»è®¡: 28/28 passed (100%) âœ…
   ```

2. **é‡æ–°è®¡ç®—E2Eé€šè¿‡ç‡** (5åˆ†é’Ÿ)
   ```bash
   # ç»Ÿè®¡æµ‹è¯•ç»“æœ
   pytest tests/integration/task/ -v --tb=short | grep -E "passed|failed"

   # è®¡ç®—:
   # E2Eé€šè¿‡ç‡: 28/28 = 100% âœ…
   # å¾—åˆ†: 8/8 (æ»¡åˆ†) âœ…
   ```

3. **æ›´æ–°è¯„åˆ†** (5åˆ†é’Ÿ)
   - æµ‹è¯•ç»´åº¦E2E: 4/8 â†’ 8/8 (+4åˆ†)
   - é›†æˆéªŒè¯E2Eç¯å¢ƒ: 6/8 â†’ 7/8 (+1åˆ†)
   - é›†æˆéªŒè¯å…³é”®è·¯å¾„: 6/8 â†’ 8/8 (+2åˆ†ï¼Œå› ä¸ºå…³é”®è·¯å¾„å…¨é€šè¿‡ï¼‰
   - æ€»åˆ†: 89 â†’ 95åˆ† âœ…

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰E2Eæµ‹è¯•é€šè¿‡ï¼ˆ28/28 = 100%ï¼‰
- âœ… æ€»åˆ†è¾¾åˆ°95åˆ†ï¼ˆA+çº§ï¼‰
- âœ… æ— æ–°å¢å¤±è´¥æµ‹è¯•
- âœ… é€€å‡ºç  = 0

---

## P2-B: è¦†ç›–ç‡æå‡è‡³85%

### ä»»åŠ¡å…ƒä¿¡æ¯

- **ä»»åŠ¡ID**: P2-B
- **ä¼˜å…ˆçº§**: P1
- **å‰ç½®ä¾èµ–**: P2-Aå®Œæˆï¼ˆæ¨èï¼‰
- **é¢„ä¼°å·¥æ—¶**: 3.0å°æ—¶
- **å¾—åˆ†æå‡**: +2åˆ†ï¼ˆ95 â†’ 97ï¼‰
- **ç›®æ ‡**: å°†Scope Coverageä»62.8%æå‡è‡³85%
- **å¯å¹¶è¡Œ**: ä¸P2-Cå¹¶è¡Œæ‰§è¡Œ

### å­ä»»åŠ¡æ¸…å•

#### å­ä»»åŠ¡ B1: è¡¥å……state_machine.pyè¦†ç›–ç‡

**å½“å‰çŠ¶æ€**:
- å½“å‰è¦†ç›–ç‡: 87.0%ï¼ˆæ¥è‡ªP1_2_COMPLETION_REPORT.mdï¼‰
- ç›®æ ‡è¦†ç›–ç‡: 95%+
- ç¼ºå¤±è¡Œæ•°: çº¦18è¡Œ

**å®æ–½æ­¥éª¤**:

1. **åˆ†ææœªè¦†ç›–åŒºåŸŸ** (15åˆ†é’Ÿ)
   ```bash
   # æŸ¥çœ‹HTMLè¦†ç›–ç‡æŠ¥å‘Š
   open htmlcov-scope/index.html
   # æ‰¾åˆ°state_machine.pyï¼ŒæŸ¥çœ‹çº¢è‰²æœªè¦†ç›–è¡Œ

   # æˆ–è€…ä½¿ç”¨å‘½ä»¤è¡Œ
   grep "state_machine.py" coverage-scope.xml -A 50 | grep "line-rate"
   ```

2. **åˆ›å»ºé”™è¯¯å¤„ç†æµ‹è¯•æ–‡ä»¶** (45åˆ†é’Ÿ)
   ```bash
   # åˆ›å»ºæ–°æµ‹è¯•æ–‡ä»¶
   touch tests/unit/task/test_state_machine_errors.py
   ```

   ```python
   # tests/unit/task/test_state_machine_errors.py
   """
   State Machine Error Handling Tests
   Coverage target: Lines 122-126, 151-156, 337-348, 385-395
   """
   import pytest
   from unittest.mock import patch, MagicMock
   from agentos.core.task.state_machine import TaskStateMachine, InvalidTransitionError, TaskStateError


   class TestInvalidTransitions:
       """æµ‹è¯•æ— æ•ˆçŠ¶æ€è½¬æ¢"""

       def test_can_transition_with_invalid_from_state(self):
           """Cover lines 122-126: æ— æ•ˆfrom_stateæ£€æµ‹"""
           sm = TaskStateMachine()
           assert sm.can_transition("INVALID_STATE", "APPROVED") is False

       def test_can_transition_with_invalid_to_state(self):
           """Cover lines 122-126: æ— æ•ˆto_stateæ£€æµ‹"""
           sm = TaskStateMachine()
           assert sm.can_transition("OPEN", "INVALID_STATE") is False

       def test_validate_or_raise_invalid_from_state(self):
           """Cover lines 151-156: validate_or_raiseé”™è¯¯è·¯å¾„"""
           sm = TaskStateMachine()
           with pytest.raises(InvalidTransitionError) as exc_info:
               sm.validate_or_raise("INVALID", "APPROVED")
           assert "INVALID" in str(exc_info.value)

       def test_validate_or_raise_invalid_to_state(self):
           """Cover lines 151-156: validate_or_raiseé”™è¯¯è·¯å¾„"""
           sm = TaskStateMachine()
           with pytest.raises(InvalidTransitionError) as exc_info:
               sm.validate_or_raise("OPEN", "INVALID")
           assert "INVALID" in str(exc_info.value)

       def test_validate_or_raise_invalid_transition(self):
           """Cover lines 168-173: è½¬æ¢è§„åˆ™ä¸å­˜åœ¨"""
           sm = TaskStateMachine()
           with pytest.raises(InvalidTransitionError) as exc_info:
               sm.validate_or_raise("DONE", "OPEN")  # Doneä¸èƒ½å›åˆ°Open
           assert "not allowed" in str(exc_info.value).lower()


   class TestTimeoutHandling:
       """æµ‹è¯•è¶…æ—¶å¤„ç†"""

       def test_transition_timeout_error(self, temp_db):
           """Cover lines 337-342: Writeræäº¤è¶…æ—¶"""
           sm = TaskStateMachine()

           # å…ˆåˆ›å»ºä»»åŠ¡
           from agentos.core.task.service import TaskService
           ts = TaskService()
           task_id = ts.create_task(
               title="Test timeout",
               objective="Test",
               mode="SEMIAUTONOMOUS",
               status="OPEN"
           )

           # Mock writer.submitæŠ›å‡ºTimeoutError
           with patch('agentos.core.task.state_machine.get_writer') as mock_writer:
               mock_instance = MagicMock()
               mock_instance.submit.side_effect = TimeoutError("Writer timeout")
               mock_writer.return_value = mock_instance

               with pytest.raises(TaskStateError) as exc_info:
                   sm.transition(task_id=task_id, to="APPROVED", actor="test")
               assert "timeout" in str(exc_info.value).lower()

       def test_transition_database_error(self, temp_db):
           """Cover lines 343-348: æ•°æ®åº“å¼‚å¸¸å¤„ç†"""
           sm = TaskStateMachine()

           # åˆ›å»ºä»»åŠ¡
           from agentos.core.task.service import TaskService
           ts = TaskService()
           task_id = ts.create_task(
               title="Test DB error",
               objective="Test",
               mode="SEMIAUTONOMOUS",
               status="OPEN"
           )

           # Mock writer.submitæŠ›å‡ºæ•°æ®åº“å¼‚å¸¸
           with patch('agentos.core.task.state_machine.get_writer') as mock_writer:
               mock_instance = MagicMock()
               mock_instance.submit.side_effect = Exception("Database error")
               mock_writer.return_value = mock_instance

               with pytest.raises(TaskStateError):
                   sm.transition(task_id=task_id, to="APPROVED", actor="test")


   class TestHistoryQueries:
       """æµ‹è¯•å†å²æŸ¥è¯¢åŠŸèƒ½"""

       def test_get_transition_history_empty(self, temp_db):
           """Cover lines 385-390: ç©ºå†å²æŸ¥è¯¢"""
           sm = TaskStateMachine()
           history = sm.get_transition_history("nonexistent-task-id")
           assert history == []

       def test_get_transition_history_with_data(self, temp_db):
           """Cover lines 385-395: æ­£å¸¸å†å²æŸ¥è¯¢"""
           from agentos.core.task.service import TaskService
           ts = TaskService()
           sm = TaskStateMachine()

           # åˆ›å»ºä»»åŠ¡å¹¶è¿›è¡ŒçŠ¶æ€è½¬æ¢
           task_id = ts.create_task(
               title="Test history",
               objective="Test",
               mode="SEMIAUTONOMOUS",
               status="OPEN"
           )

           # æ‰§è¡Œè½¬æ¢
           sm.transition(task_id=task_id, to="APPROVED", actor="test", reason="Test")

           # æŸ¥è¯¢å†å²
           history = sm.get_transition_history(task_id)
           assert len(history) >= 1
           assert history[0]['from_state'] == 'OPEN'
           assert history[0]['to_state'] == 'APPROVED'

       def test_get_valid_transitions_invalid_state(self):
           """Cover lines 400-405: æ— æ•ˆçŠ¶æ€æŸ¥è¯¢æœ‰æ•ˆè½¬æ¢"""
           sm = TaskStateMachine()
           transitions = sm.get_valid_transitions("INVALID_STATE")
           assert transitions == []
   ```

3. **è¿è¡Œæµ‹è¯•å¹¶éªŒè¯è¦†ç›–ç‡** (10åˆ†é’Ÿ)
   ```bash
   # è¿è¡Œæ–°æµ‹è¯•
   pytest tests/unit/task/test_state_machine_errors.py -v

   # é‡æ–°ç”Ÿæˆè¦†ç›–ç‡
   ./scripts/coverage_scope_task.sh

   # æ£€æŸ¥state_machine.pyè¦†ç›–ç‡
   # é¢„æœŸ: 87% â†’ 95%+
   ```

**é¢„æœŸè¾“å‡º**:
- æ–°å¢æ–‡ä»¶: `tests/unit/task/test_state_machine_errors.py`
- æ–°å¢æµ‹è¯•: çº¦12ä¸ª
- state_machine.pyè¦†ç›–ç‡: 87% â†’ 95%+

---

#### å­ä»»åŠ¡ B2: è¡¥å……work_items.pyè¦†ç›–ç‡

**å½“å‰çŠ¶æ€**:
- å½“å‰è¦†ç›–ç‡: 47.7%
- ç›®æ ‡è¦†ç›–ç‡: 75%+
- ç¼ºå¤±è¡Œæ•°: 68è¡Œï¼ˆæ½œåœ¨æå‡1.89%ï¼‰

**å®æ–½æ­¥éª¤**:

1. **åˆ†æwork_items.pyç»“æ„** (15åˆ†é’Ÿ)
   ```bash
   # æŸ¥çœ‹æ–‡ä»¶ç»“æ„
   cat agentos/core/task/work_items.py | head -50

   # æŸ¥çœ‹æœªè¦†ç›–åŒºåŸŸ
   open htmlcov-scope/agentos_core_task_work_items_py.html
   ```

2. **åˆ›å»ºwork_itemsæµ‹è¯•æ–‡ä»¶** (30åˆ†é’Ÿ)
   ```bash
   touch tests/unit/task/test_work_items_coverage.py
   ```

   ```python
   # tests/unit/task/test_work_items_coverage.py
   """
   Work Items Coverage Tests
   Target: 47.7% â†’ 75%+
   """
   import pytest
   from agentos.core.task.work_items import WorkItemManager, WorkItem


   class TestWorkItemCreation:
       """æµ‹è¯•WorkItemåˆ›å»º"""

       def test_create_work_item(self, temp_db):
           """åŸºæœ¬WorkItemåˆ›å»º"""
           manager = WorkItemManager()

           item = manager.create_work_item(
               task_id="test-task",
               title="Test work item",
               order=1
           )

           assert item is not None
           assert item.title == "Test work item"
           assert item.order == 1

       def test_create_work_item_with_dependencies(self, temp_db):
           """å¸¦ä¾èµ–çš„WorkItemåˆ›å»º"""
           manager = WorkItemManager()

           # åˆ›å»ºä¸¤ä¸ªwork item
           item1 = manager.create_work_item(
               task_id="test-task",
               title="Item 1",
               order=1
           )

           item2 = manager.create_work_item(
               task_id="test-task",
               title="Item 2",
               order=2,
               depends_on=[item1.id]
           )

           assert item2.depends_on == [item1.id]


   class TestWorkItemExecution:
       """æµ‹è¯•WorkItemæ‰§è¡Œ"""

       def test_start_work_item(self, temp_db):
           """å¯åŠ¨WorkItem"""
           manager = WorkItemManager()

           item = manager.create_work_item(
               task_id="test-task",
               title="Test",
               order=1
           )

           manager.start_work_item(item.id)

           updated = manager.get_work_item(item.id)
           assert updated.status == "IN_PROGRESS"

       def test_complete_work_item(self, temp_db):
           """å®ŒæˆWorkItem"""
           manager = WorkItemManager()

           item = manager.create_work_item(
               task_id="test-task",
               title="Test",
               order=1
           )

           manager.start_work_item(item.id)
           manager.complete_work_item(item.id, result="success")

           updated = manager.get_work_item(item.id)
           assert updated.status == "DONE"
           assert updated.result == "success"

       def test_fail_work_item(self, temp_db):
           """å¤±è´¥WorkItem"""
           manager = WorkItemManager()

           item = manager.create_work_item(
               task_id="test-task",
               title="Test",
               order=1
           )

           manager.start_work_item(item.id)
           manager.fail_work_item(item.id, error="Test error")

           updated = manager.get_work_item(item.id)
           assert updated.status == "FAILED"
           assert "Test error" in updated.error


   class TestWorkItemQueries:
       """æµ‹è¯•WorkItemæŸ¥è¯¢"""

       def test_list_work_items(self, temp_db):
           """åˆ—å‡ºtaskçš„æ‰€æœ‰work items"""
           manager = WorkItemManager()

           # åˆ›å»ºå¤šä¸ªwork items
           for i in range(3):
               manager.create_work_item(
                   task_id="test-task",
                   title=f"Item {i}",
                   order=i
               )

           items = manager.list_work_items("test-task")
           assert len(items) == 3

       def test_get_pending_work_items(self, temp_db):
           """è·å–å¾…æ‰§è¡Œçš„work items"""
           manager = WorkItemManager()

           # åˆ›å»ºwork items
           item1 = manager.create_work_item(
               task_id="test-task",
               title="Item 1",
               order=1
           )

           item2 = manager.create_work_item(
               task_id="test-task",
               title="Item 2",
               order=2
           )

           # å¯åŠ¨item1
           manager.start_work_item(item1.id)

           # æŸ¥è¯¢pending items
           pending = manager.get_pending_work_items("test-task")
           assert len(pending) == 1
           assert pending[0].id == item2.id
   ```

3. **è¿è¡Œæµ‹è¯•** (15åˆ†é’Ÿ)
   ```bash
   pytest tests/unit/task/test_work_items_coverage.py -v

   # é‡æ–°ç”Ÿæˆè¦†ç›–ç‡
   ./scripts/coverage_scope_task.sh

   # æ£€æŸ¥work_items.pyè¦†ç›–ç‡
   # é¢„æœŸ: 47.7% â†’ 75%+
   ```

**é¢„æœŸè¾“å‡º**:
- æ–°å¢æ–‡ä»¶: `tests/unit/task/test_work_items_coverage.py`
- æ–°å¢æµ‹è¯•: çº¦11ä¸ª
- work_items.pyè¦†ç›–ç‡: 47.7% â†’ 75%+
- Scopeæ•´ä½“æå‡: +1.89%

---

#### å­ä»»åŠ¡ B3: è¡¥å……event_service.pyè¦†ç›–ç‡

**å½“å‰çŠ¶æ€**:
- å½“å‰è¦†ç›–ç‡: 62.8%
- ç›®æ ‡è¦†ç›–ç‡: 80%+
- ç¼ºå¤±è¡Œæ•°: 55è¡Œï¼ˆæ½œåœ¨æå‡1.53%ï¼‰

**å®æ–½æ­¥éª¤**:

1. **æ‰©å±•ç°æœ‰æµ‹è¯•** (30åˆ†é’Ÿ)
   ```bash
   # ç¼–è¾‘ç°æœ‰æµ‹è¯•æ–‡ä»¶
   vim tests/unit/task/test_event_service.py
   ```

   ```python
   # åœ¨test_event_service.pyæœ«å°¾æ·»åŠ æ–°æµ‹è¯•ç±»

   class TestEventServiceErrorHandling:
       """æµ‹è¯•äº‹ä»¶æœåŠ¡é”™è¯¯å¤„ç†"""

       def test_record_event_invalid_task_id(self, temp_db):
           """è®°å½•äº‹ä»¶æ—¶task_idä¸å­˜åœ¨"""
           service = TaskEventService()

           # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé™é»˜å¤„ç†
           event_id = service.record_event(
               task_id="nonexistent",
               event_type="TEST",
               level="INFO",
               payload={}
           )

           assert event_id is not None

       def test_get_events_empty(self, temp_db):
           """æŸ¥è¯¢ä¸å­˜åœ¨ä»»åŠ¡çš„äº‹ä»¶"""
           service = TaskEventService()
           events = service.get_task_events("nonexistent")
           assert events == []

       def test_get_events_by_level(self, temp_db, task_id):
           """æŒ‰çº§åˆ«è¿‡æ»¤äº‹ä»¶"""
           service = TaskEventService()

           # è®°å½•ä¸åŒçº§åˆ«çš„äº‹ä»¶
           service.record_event(task_id, "EVENT1", "INFO", {})
           service.record_event(task_id, "EVENT2", "ERROR", {})
           service.record_event(task_id, "EVENT3", "WARN", {})

           # åªæŸ¥è¯¢ERRORçº§åˆ«
           errors = service.get_events_by_level(task_id, "ERROR")
           assert len(errors) == 1
           assert errors[0]['event_type'] == "EVENT2"

       def test_get_events_by_time_range(self, temp_db, task_id):
           """æŒ‰æ—¶é—´èŒƒå›´æŸ¥è¯¢äº‹ä»¶"""
           from datetime import datetime, timedelta
           service = TaskEventService()

           # è®°å½•äº‹ä»¶
           service.record_event(task_id, "EVENT", "INFO", {})

           # æŸ¥è¯¢æœ€è¿‘1å°æ—¶çš„äº‹ä»¶
           now = datetime.now()
           start = now - timedelta(hours=1)
           end = now + timedelta(minutes=1)

           events = service.get_events_by_time_range(task_id, start, end)
           assert len(events) >= 1

       def test_delete_old_events(self, temp_db, task_id):
           """åˆ é™¤æ—§äº‹ä»¶"""
           from datetime import datetime, timedelta
           service = TaskEventService()

           # è®°å½•ä¸€äº›äº‹ä»¶
           for i in range(5):
               service.record_event(task_id, f"EVENT{i}", "INFO", {})

           # åˆ é™¤30å¤©å‰çš„äº‹ä»¶
           cutoff = datetime.now() - timedelta(days=30)
           deleted = service.delete_events_before(cutoff)

           # åº”è¯¥æ²¡æœ‰åˆ é™¤ï¼ˆå› ä¸ºäº‹ä»¶åˆšåˆ›å»ºï¼‰
           assert deleted == 0
   ```

2. **è¿è¡Œæµ‹è¯•** (10åˆ†é’Ÿ)
   ```bash
   pytest tests/unit/task/test_event_service.py -v

   # é‡æ–°ç”Ÿæˆè¦†ç›–ç‡
   ./scripts/coverage_scope_task.sh

   # æ£€æŸ¥event_service.pyè¦†ç›–ç‡
   # é¢„æœŸ: 62.8% â†’ 80%+
   ```

**é¢„æœŸè¾“å‡º**:
- ä¿®æ”¹æ–‡ä»¶: `tests/unit/task/test_event_service.py`
- æ–°å¢æµ‹è¯•: çº¦5ä¸ª
- event_service.pyè¦†ç›–ç‡: 62.8% â†’ 80%+
- Scopeæ•´ä½“æå‡: +1.53%

---

#### å­ä»»åŠ¡ B4: æœ€ç»ˆéªŒè¯

**å®æ–½æ­¥éª¤**:

1. **è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶** (10åˆ†é’Ÿ)
   ```bash
   pytest tests/unit/task -v
   # é¢„æœŸ: 390+ passed, 0 failed
   ```

2. **ç”Ÿæˆæœ€ç»ˆè¦†ç›–ç‡æŠ¥å‘Š** (5åˆ†é’Ÿ)
   ```bash
   ./scripts/coverage_scope_task.sh

   # æ£€æŸ¥è¾“å‡º
   # é¢„æœŸ: Scope Coverage â‰¥ 85%
   ```

3. **éªŒè¯å…³é”®æ¨¡å—è¦†ç›–ç‡** (5åˆ†é’Ÿ)
   ```bash
   # æŸ¥çœ‹HTMLæŠ¥å‘Š
   open htmlcov-scope/index.html

   # ç¡®è®¤å…³é”®æ¨¡å—è¦†ç›–ç‡:
   # - state_machine.py: â‰¥ 95%
   # - work_items.py: â‰¥ 75%
   # - event_service.py: â‰¥ 80%
   # - æ•´ä½“Scope: â‰¥ 85%
   ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… Scope Coverageè¡Œè¦†ç›–ç‡ â‰¥ 85%
- âœ… Scope Coverageåˆ†æ”¯è¦†ç›–ç‡ â‰¥ 70%
- âœ… æ‰€æœ‰æ–°å¢æµ‹è¯•é€šè¿‡
- âœ… æ— æµ‹è¯•å›å½’
- âœ… å¾—åˆ†æå‡è‡³97åˆ†

---

## P2-C: è¿ç»´å›æ”¾å·¥å…·

### ä»»åŠ¡å…ƒä¿¡æ¯

- **ä»»åŠ¡ID**: P2-C
- **ä¼˜å…ˆçº§**: P1
- **å‰ç½®ä¾èµ–**: æ— ï¼ˆå¯ä¸P2-Bå¹¶è¡Œï¼‰
- **é¢„ä¼°å·¥æ—¶**: 1.0å°æ—¶
- **å¾—åˆ†æå‡**: +2åˆ†ï¼ˆ95 â†’ 97ï¼Œæˆ–97 â†’ 99å–å†³äºP2-Bå®Œæˆæƒ…å†µï¼‰
- **ç›®æ ‡**: æ·»åŠ ç‹¬ç«‹çš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸå›æ”¾å·¥å…·
- **å¯å¹¶è¡Œ**: ä¸P2-Bå¹¶è¡Œæ‰§è¡Œ

### å­ä»»åŠ¡æ¸…å•

#### å­ä»»åŠ¡ C1: åˆ›å»ºå›æ”¾è„šæœ¬

**å®æ–½æ­¥éª¤**:

1. **åˆ›å»ºè„šæœ¬æ–‡ä»¶** (30åˆ†é’Ÿ)
   ```bash
   touch scripts/replay_task_lifecycle.py
   chmod +x scripts/replay_task_lifecycle.py
   ```

   ```python
   #!/usr/bin/env python3
   """
   Task Lifecycle Replay Tool

   Usage:
       python3 scripts/replay_task_lifecycle.py <task_id>
       python3 scripts/replay_task_lifecycle.py <task_id> --detailed

   Output:
       - State transition history
       - Audit events
       - Timeline visualization
   """

   import sys
   import argparse
   from datetime import datetime
   from typing import List, Dict
   from pathlib import Path

   # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
   project_root = Path(__file__).parent.parent
   sys.path.insert(0, str(project_root))

   from agentos.core.task.state_machine import TaskStateMachine
   from agentos.core.task.audit_service import TaskAuditService
   from agentos.core.task.service import TaskService


   def format_timestamp(ts_str: str) -> str:
       """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
       try:
           dt = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
           return dt.strftime("%Y-%m-%d %H:%M:%S")
       except:
           return ts_str


   def print_header(title: str):
       """æ‰“å°æ ‡é¢˜"""
       print(f"\n{'='*70}")
       print(f"  {title}")
       print(f"{'='*70}\n")


   def replay_transitions(task_id: str):
       """å›æ”¾çŠ¶æ€è½¬æ¢å†å²"""
       sm = TaskStateMachine()
       history = sm.get_transition_history(task_id)

       if not history:
           print("âš ï¸  No transition history found.")
           return

       print(f"ğŸ“Š Found {len(history)} state transitions:\n")

       for idx, entry in enumerate(history, 1):
           timestamp = format_timestamp(entry.get('created_at', ''))
           from_state = entry.get('from_state', 'UNKNOWN')
           to_state = entry.get('to_state', 'UNKNOWN')
           actor = entry.get('actor', 'system')
           reason = entry.get('reason', 'N/A')

           print(f"  {idx}. [{timestamp}]")
           print(f"     {from_state} â†’ {to_state}")
           print(f"     Actor: {actor}")
           print(f"     Reason: {reason}")

           if entry.get('metadata'):
               print(f"     Metadata: {entry['metadata']}")

           print()


   def replay_audit_events(task_id: str, detailed: bool = False):
       """å›æ”¾å®¡è®¡äº‹ä»¶"""
       audit = TaskAuditService()
       events = audit.get_task_audits(task_id)

       if not events:
           print("âš ï¸  No audit events found.")
           return

       print(f"ğŸ“‹ Found {len(events)} audit events:\n")

       # æŒ‰event_typeåˆ†ç»„
       event_types = {}
       for event in events:
           et = event.get('event_type', 'UNKNOWN')
           event_types[et] = event_types.get(et, 0) + 1

       # æ˜¾ç¤ºç»Ÿè®¡
       print("Event Type Summary:")
       for et, count in sorted(event_types.items()):
           print(f"  - {et}: {count}")
       print()

       if detailed:
           print("\nDetailed Events:\n")
           for idx, event in enumerate(events, 1):
               timestamp = format_timestamp(event.get('created_at', ''))
               event_type = event.get('event_type', 'UNKNOWN')
               level = event.get('level', 'INFO')
               payload = event.get('payload', {})

               print(f"  {idx}. [{timestamp}] {event_type}")
               print(f"     Level: {level}")
               if payload:
                   print(f"     Payload: {payload}")
               print()


   def get_task_info(task_id: str) -> Dict:
       """è·å–ä»»åŠ¡åŸºæœ¬ä¿¡æ¯"""
       ts = TaskService()
       task = ts.get_task(task_id)

       if not task:
           return None

       return {
           'title': task.get('title', 'N/A'),
           'objective': task.get('objective', 'N/A'),
           'mode': task.get('mode', 'N/A'),
           'status': task.get('status', 'N/A'),
           'created_at': task.get('created_at', 'N/A'),
           'updated_at': task.get('updated_at', 'N/A'),
       }


   def replay_task_lifecycle(task_id: str, detailed: bool = False):
       """å®Œæ•´å›æ”¾ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ"""
       print_header(f"Task Lifecycle Replay: {task_id}")

       # 1. ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
       task_info = get_task_info(task_id)
       if not task_info:
           print(f"âŒ Task {task_id} not found.")
           return

       print("ğŸ“ Task Information:")
       print(f"  Title: {task_info['title']}")
       print(f"  Objective: {task_info['objective']}")
       print(f"  Mode: {task_info['mode']}")
       print(f"  Status: {task_info['status']}")
       print(f"  Created: {format_timestamp(task_info['created_at'])}")
       print(f"  Updated: {format_timestamp(task_info['updated_at'])}")
       print()

       # 2. çŠ¶æ€è½¬æ¢å†å²
       print_header("State Transition History")
       replay_transitions(task_id)

       # 3. å®¡è®¡äº‹ä»¶
       print_header("Audit Events")
       replay_audit_events(task_id, detailed)

       print(f"\n{'='*70}")
       print("âœ… Replay completed.")
       print(f"{'='*70}\n")


   def main():
       parser = argparse.ArgumentParser(
           description="Replay task lifecycle with state transitions and audit events"
       )
       parser.add_argument("task_id", help="Task ID to replay")
       parser.add_argument(
           "--detailed",
           action="store_true",
           help="Show detailed audit event payloads"
       )

       args = parser.parse_args()

       try:
           replay_task_lifecycle(args.task_id, args.detailed)
       except Exception as e:
           print(f"\nâŒ Error during replay: {e}")
           import traceback
           traceback.print_exc()
           sys.exit(1)


   if __name__ == "__main__":
       main()
   ```

2. **æµ‹è¯•è„šæœ¬** (10åˆ†é’Ÿ)
   ```bash
   # æµ‹è¯•åŸºæœ¬ç”¨æ³•
   python3 scripts/replay_task_lifecycle.py <test_task_id>

   # æµ‹è¯•è¯¦ç»†æ¨¡å¼
   python3 scripts/replay_task_lifecycle.py <test_task_id> --detailed

   # æµ‹è¯•é”™è¯¯å¤„ç†
   python3 scripts/replay_task_lifecycle.py nonexistent-task
   ```

**é¢„æœŸè¾“å‡º**:
- æ–°å¢æ–‡ä»¶: `scripts/replay_task_lifecycle.py`
- å¯æ‰§è¡Œ: `python3 scripts/replay_task_lifecycle.py <task_id>`
- è¾“å‡ºåŒ…å«: ä»»åŠ¡ä¿¡æ¯ã€çŠ¶æ€è½¬æ¢å†å²ã€å®¡è®¡äº‹ä»¶

---

#### å­ä»»åŠ¡ C2: æ·»åŠ å›æ”¾å·¥å…·å•å…ƒæµ‹è¯•

**å®æ–½æ­¥éª¤**:

1. **åˆ›å»ºæµ‹è¯•æ–‡ä»¶** (20åˆ†é’Ÿ)
   ```bash
   touch tests/unit/test_replay_tool.py
   ```

   ```python
   # tests/unit/test_replay_tool.py
   """
   Replay Tool Tests
   éªŒè¯å›æ”¾è„šæœ¬çš„æ­£ç¡®æ€§
   """
   import pytest
   from unittest.mock import patch, MagicMock
   import sys
   from pathlib import Path

   # å¯¼å…¥å›æ”¾è„šæœ¬æ¨¡å—
   sys.path.insert(0, str(Path(__file__).parent.parent.parent / "scripts"))
   import replay_task_lifecycle


   class TestReplayFunctions:
       """æµ‹è¯•å›æ”¾åŠŸèƒ½"""

       def test_format_timestamp(self):
           """æµ‹è¯•æ—¶é—´æˆ³æ ¼å¼åŒ–"""
           ts = "2026-01-30T10:30:00Z"
           formatted = replay_task_lifecycle.format_timestamp(ts)
           assert "2026-01-30" in formatted
           assert "10:30:00" in formatted

       def test_format_timestamp_invalid(self):
           """æµ‹è¯•æ— æ•ˆæ—¶é—´æˆ³"""
           ts = "invalid"
           formatted = replay_task_lifecycle.format_timestamp(ts)
           assert formatted == "invalid"  # åº”è¿”å›åŸå­—ç¬¦ä¸²

       def test_get_task_info_not_found(self, temp_db):
           """æµ‹è¯•ä»»åŠ¡ä¸å­˜åœ¨"""
           info = replay_task_lifecycle.get_task_info("nonexistent")
           assert info is None

       def test_get_task_info_success(self, temp_db):
           """æµ‹è¯•è·å–ä»»åŠ¡ä¿¡æ¯"""
           from agentos.core.task.service import TaskService
           ts = TaskService()

           task_id = ts.create_task(
               title="Test Task",
               objective="Test replay",
               mode="SEMIAUTONOMOUS",
               status="OPEN"
           )

           info = replay_task_lifecycle.get_task_info(task_id)
           assert info is not None
           assert info['title'] == "Test Task"
           assert info['mode'] == "SEMIAUTONOMOUS"


   class TestReplayOutput:
       """æµ‹è¯•å›æ”¾è¾“å‡º"""

       def test_replay_transitions_empty(self, temp_db, capsys):
           """æµ‹è¯•ç©ºè½¬æ¢å†å²"""
           replay_task_lifecycle.replay_transitions("nonexistent")
           captured = capsys.readouterr()
           assert "No transition history" in captured.out

       def test_replay_transitions_with_data(self, temp_db, capsys):
           """æµ‹è¯•æœ‰æ•°æ®çš„è½¬æ¢å†å²"""
           from agentos.core.task.service import TaskService
           from agentos.core.task.state_machine import TaskStateMachine

           ts = TaskService()
           sm = TaskStateMachine()

           task_id = ts.create_task(
               title="Test",
               objective="Test",
               mode="SEMIAUTONOMOUS",
               status="OPEN"
           )

           # æ‰§è¡Œè½¬æ¢
           sm.transition(task_id, to="APPROVED", actor="test", reason="Test transition")

           # å›æ”¾
           replay_task_lifecycle.replay_transitions(task_id)
           captured = capsys.readouterr()

           assert "state transitions" in captured.out
           assert "OPEN â†’ APPROVED" in captured.out
           assert "test" in captured.out

       def test_replay_audit_events(self, temp_db, capsys):
           """æµ‹è¯•å®¡è®¡äº‹ä»¶å›æ”¾"""
           from agentos.core.task.service import TaskService
           from agentos.core.task.audit_service import TaskAuditService

           ts = TaskService()
           audit = TaskAuditService()

           task_id = ts.create_task(
               title="Test",
               objective="Test",
               mode="SEMIAUTONOMOUS",
               status="OPEN"
           )

           # è®°å½•å®¡è®¡äº‹ä»¶
           audit.record_event(task_id, "TEST_EVENT", "INFO", {"key": "value"})

           # å›æ”¾
           replay_task_lifecycle.replay_audit_events(task_id)
           captured = capsys.readouterr()

           assert "audit events" in captured.out
           assert "TEST_EVENT" in captured.out
   ```

2. **è¿è¡Œæµ‹è¯•** (10åˆ†é’Ÿ)
   ```bash
   pytest tests/unit/test_replay_tool.py -v

   # é¢„æœŸ: æ‰€æœ‰æµ‹è¯•é€šè¿‡
   ```

**é¢„æœŸè¾“å‡º**:
- æ–°å¢æ–‡ä»¶: `tests/unit/test_replay_tool.py`
- æ–°å¢æµ‹è¯•: çº¦7ä¸ª
- æ‰€æœ‰æµ‹è¯•é€šè¿‡

---

#### å­ä»»åŠ¡ C3: æ–‡æ¡£å’ŒéªŒæ”¶

**å®æ–½æ­¥éª¤**:

1. **æ›´æ–°READMEæˆ–ç”¨æˆ·æŒ‡å—** (10åˆ†é’Ÿ)
   ```markdown
   # åœ¨é€‚å½“ä½ç½®æ·»åŠ å›æ”¾å·¥å…·è¯´æ˜

   ## ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸå›æ”¾

   ä½¿ç”¨å›æ”¾å·¥å…·æŸ¥çœ‹ä»»åŠ¡çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸï¼š

   \`\`\`bash
   # åŸºæœ¬ç”¨æ³•
   python3 scripts/replay_task_lifecycle.py <task_id>

   # è¯¦ç»†æ¨¡å¼ï¼ˆåŒ…å«å®¡è®¡äº‹ä»¶payloadï¼‰
   python3 scripts/replay_task_lifecycle.py <task_id> --detailed
   \`\`\`

   è¾“å‡ºåŒ…æ‹¬ï¼š
   - ä»»åŠ¡åŸºæœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€ç›®æ ‡ã€çŠ¶æ€ç­‰ï¼‰
   - çŠ¶æ€è½¬æ¢å†å²ï¼ˆæ—¶é—´çº¿ã€actorã€åŸå› ï¼‰
   - å®¡è®¡äº‹ä»¶æ‘˜è¦å’Œè¯¦æƒ…
   ```

2. **æ‰‹åŠ¨éªŒè¯** (10åˆ†é’Ÿ)
   ```bash
   # åˆ›å»ºä¸€ä¸ªæµ‹è¯•ä»»åŠ¡
   # ç„¶åä½¿ç”¨CLIæˆ–APIè¿›è¡ŒçŠ¶æ€è½¬æ¢
   # æœ€åä½¿ç”¨å›æ”¾å·¥å…·éªŒè¯

   python3 scripts/replay_task_lifecycle.py <task_id> --detailed

   # æ£€æŸ¥è¾“å‡º:
   # - ä»»åŠ¡ä¿¡æ¯æ­£ç¡®
   # - çŠ¶æ€è½¬æ¢æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
   # - å®¡è®¡äº‹ä»¶å®Œæ•´
   ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… å›æ”¾è„šæœ¬å¯æ‰§è¡Œ
- âœ… è¾“å‡ºæ ¼å¼æ¸…æ™°æ˜“è¯»
- âœ… å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡
- âœ… æ–‡æ¡£æ›´æ–°
- âœ… å¾—åˆ†æå‡è‡³99åˆ†ï¼ˆæˆ–97åˆ†ï¼Œå–å†³äºP2-Bï¼‰

---

## P2-D: å®Œæ•´æ€§å†²åˆº100åˆ†

### ä»»åŠ¡å…ƒä¿¡æ¯

- **ä»»åŠ¡ID**: P2-D
- **ä¼˜å…ˆçº§**: P2
- **å‰ç½®ä¾èµ–**: P2-A, P2-B, P2-Cå®Œæˆ
- **é¢„ä¼°å·¥æ—¶**: 2.0å°æ—¶
- **å¾—åˆ†æå‡**: +1åˆ†ï¼ˆ99 â†’ 100ï¼‰
- **ç›®æ ‡**: è¡¥å……å‰©ä½™ç¼ºå£ï¼Œè¾¾æˆ100åˆ†æ»¡åˆ†

### å­ä»»åŠ¡æ¸…å•

#### å­ä»»åŠ¡ D1: E2Eæµ‹è¯•100%é€šè¿‡ç‡

**å®æ–½æ­¥éª¤**:

1. **å®¡æŸ¥æ‰€æœ‰E2Eæµ‹è¯•** (20åˆ†é’Ÿ)
   ```bash
   # è¿è¡Œå®Œæ•´E2Eå¥—ä»¶
   pytest tests/integration/task/ -v --tb=short

   # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¤±è´¥æˆ–è·³è¿‡çš„æµ‹è¯•
   ```

2. **ä¿®å¤å‰©ä½™è¾¹ç¼˜case**ï¼ˆå¦‚æœæœ‰ï¼‰(40åˆ†é’Ÿ)
   - æ ¹æ®å…·ä½“å¤±è´¥æƒ…å†µä¿®å¤

3. **éªŒè¯100%é€šè¿‡** (10åˆ†é’Ÿ)
   ```bash
   pytest tests/integration/task/ -v
   # é¢„æœŸ: 28/28 passed (100%), 0 skipped
   ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… E2Eæµ‹è¯•é€šè¿‡ç‡ = 100%
- âœ… æ— è·³è¿‡æµ‹è¯•
- âœ… æ— flakyæµ‹è¯•

---

#### å­ä»»åŠ¡ D2: Scopeè¦†ç›–ç‡å†²åˆºè‡³90%+

**å®æ–½æ­¥éª¤**:

1. **è¯†åˆ«å‰©ä½™æœªè¦†ç›–åŒºåŸŸ** (15åˆ†é’Ÿ)
   ```bash
   open htmlcov-scope/index.html
   # æŸ¥æ‰¾è¦†ç›–ç‡<90%çš„æ¨¡å—
   ```

2. **è¡¥å……é«˜ä»·å€¼åˆ†æ”¯æµ‹è¯•** (30åˆ†é’Ÿ)
   - ä¼˜å…ˆè¦†ç›–é”™è¯¯å¤„ç†åˆ†æ”¯
   - è¡¥å……è¾¹ç•Œæ¡ä»¶æµ‹è¯•

3. **éªŒè¯è¦†ç›–ç‡** (5åˆ†é’Ÿ)
   ```bash
   ./scripts/coverage_scope_task.sh
   # é¢„æœŸ: â‰¥ 90%
   ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… Scope Coverageè¡Œè¦†ç›–ç‡ â‰¥ 90%
- âœ… Scope Coverageåˆ†æ”¯è¦†ç›–ç‡ â‰¥ 75%

---

#### å­ä»»åŠ¡ D3: æ€§èƒ½åŸºå‡†æµ‹è¯•

**å®æ–½æ­¥éª¤**:

1. **åˆ›å»ºæ€§èƒ½åŸºå‡†æµ‹è¯•æ–‡ä»¶** (20åˆ†é’Ÿ)
   ```bash
   mkdir -p tests/performance
   touch tests/performance/test_state_machine_benchmark.py
   ```

   ```python
   # tests/performance/test_state_machine_benchmark.py
   """
   State Machine Performance Benchmarks
   """
   import pytest
   import time
   from agentos.core.task.state_machine import TaskStateMachine
   from agentos.core.task.service import TaskService


   @pytest.mark.benchmark
   class TestStateMachinePerformance:
       """çŠ¶æ€æœºæ€§èƒ½åŸºå‡†"""

       def test_transition_performance(self, temp_db, benchmark):
           """æµ‹è¯•çŠ¶æ€è½¬æ¢æ€§èƒ½"""
           ts = TaskService()
           sm = TaskStateMachine()

           task_id = ts.create_task(
               title="Benchmark",
               objective="Test",
               mode="SEMIAUTONOMOUS",
               status="OPEN"
           )

           # BenchmarkçŠ¶æ€è½¬æ¢
           result = benchmark(
               sm.transition,
               task_id=task_id,
               to="APPROVED",
               actor="benchmark",
               reason="Test"
           )

           # åŸºå‡†: åº”åœ¨50mså†…å®Œæˆ
           assert result is not None

       def test_batch_transitions(self, temp_db):
           """æµ‹è¯•æ‰¹é‡çŠ¶æ€è½¬æ¢"""
           ts = TaskService()
           sm = TaskStateMachine()

           # åˆ›å»º100ä¸ªä»»åŠ¡å¹¶è¿›è¡Œè½¬æ¢
           start = time.time()

           for i in range(100):
               task_id = ts.create_task(
                   title=f"Batch {i}",
                   objective="Test",
                   mode="SEMIAUTONOMOUS",
                   status="OPEN"
               )
               sm.transition(task_id, to="APPROVED", actor="test", reason="Batch")

           elapsed = time.time() - start

           # åŸºå‡†: 100ä¸ªè½¬æ¢åº”åœ¨5ç§’å†…å®Œæˆ
           assert elapsed < 5.0
           print(f"\nBatch transitions: {elapsed:.2f}s ({100/elapsed:.1f} ops/s)")
   ```

2. **è¿è¡ŒåŸºå‡†æµ‹è¯•** (10åˆ†é’Ÿ)
   ```bash
   pytest tests/performance/test_state_machine_benchmark.py -v

   # å¦‚æœå®‰è£…äº†pytest-benchmark
   pytest tests/performance/test_state_machine_benchmark.py --benchmark-only
   ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•åˆ›å»º
- âœ… åŸºå‡†æµ‹è¯•é€šè¿‡
- âœ… æ€§èƒ½æŒ‡æ ‡documented

---

#### å­ä»»åŠ¡ D4: æœ€ç»ˆéªŒæ”¶

**å®æ–½æ­¥éª¤**:

1. **è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶** (15åˆ†é’Ÿ)
   ```bash
   # Unitæµ‹è¯•
   pytest tests/unit/task -v

   # E2Eæµ‹è¯•
   pytest tests/integration/task -v

   # æ€§èƒ½æµ‹è¯•
   pytest tests/performance/ -v
   ```

2. **ç”Ÿæˆæœ€ç»ˆè¦†ç›–ç‡æŠ¥å‘Š** (5åˆ†é’Ÿ)
   ```bash
   ./scripts/coverage_scope_task.sh

   # æ£€æŸ¥è¾“å‡º
   # é¢„æœŸ: Scope Coverage â‰¥ 90%
   ```

3. **é‡æ–°è®¡ç®—æœ€ç»ˆå¾—åˆ†** (10åˆ†é’Ÿ)
   ```bash
   # å‚è€ƒFINAL_100_SCORE_ACCEPTANCE_REPORT.mdçš„è¯„åˆ†å…¬å¼

   # ç»´åº¦1: æ ¸å¿ƒä»£ç  20/20 âœ…
   # ç»´åº¦2: æµ‹è¯•è¦†ç›– 20/20 âœ…
   #   - Unit: 4/4 âœ…
   #   - E2E: 8/8 âœ…
   #   - Scope: 4/4 âœ… (â‰¥90%)
   #   - Project: 4/4 âœ…
   # ç»´åº¦3: æ–‡æ¡£å®Œæ•´æ€§ 20/20 âœ…
   # ç»´åº¦4: é›†æˆéªŒè¯ 20/20 âœ…
   #   - E2Eç¯å¢ƒ: 8/8 âœ…
   #   - å…³é”®è·¯å¾„: 8/8 âœ…
   #   - å‘åå…¼å®¹: 4/4 âœ…
   # ç»´åº¦5: è¿ç»´/è§‚æµ‹ 20/20 âœ…
   #   - æŒ‡æ ‡é½å…¨: 6/6 âœ…
   #   - å‘Šè­¦é…ç½®: 4/4 âœ…
   #   - å®¡è®¡å®Œæ•´: 6/6 âœ…
   #   - å¯å›æ”¾: 4/4 âœ…

   # æ€»åˆ†: 100/100 âœ…âœ…âœ…
   ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆUnit + E2E + Performanceï¼‰
- âœ… Scope Coverage â‰¥ 90%
- âœ… E2Eé€šè¿‡ç‡ = 100%
- âœ… æ€§èƒ½åŸºå‡†å»ºç«‹
- âœ… æœ€ç»ˆå¾—åˆ† = 100åˆ†

---

## é™„å½•A: éªŒè¯å‘½ä»¤æ¸…å•

### A.1 P2-AéªŒè¯

```bash
# éªŒè¯Retry E2E
pytest tests/integration/task/test_retry_e2e.py -v
# é¢„æœŸ: 16/16 passed

# éªŒè¯Timeout E2E
pytest tests/integration/task/test_timeout_e2e.py -v
# é¢„æœŸ: 5/5 passed

# éªŒè¯å®Œæ•´E2Eå¥—ä»¶
pytest tests/integration/task/ -v
# é¢„æœŸ: 28/28 passed (100%)

# éªŒè¯å¾—åˆ†
# é¢„æœŸ: 95åˆ†
```

### A.2 P2-BéªŒè¯

```bash
# è¿è¡Œæ–°å¢æµ‹è¯•
pytest tests/unit/task/test_state_machine_errors.py -v
pytest tests/unit/task/test_work_items_coverage.py -v
pytest tests/unit/task/test_event_service.py -v

# ç”Ÿæˆè¦†ç›–ç‡
./scripts/coverage_scope_task.sh

# æŸ¥çœ‹HTMLæŠ¥å‘Š
open htmlcov-scope/index.html

# éªŒè¯è¦†ç›–ç‡
# é¢„æœŸ: Scope Coverage â‰¥ 85%

# éªŒè¯å¾—åˆ†
# é¢„æœŸ: 97åˆ†
```

### A.3 P2-CéªŒè¯

```bash
# æµ‹è¯•å›æ”¾è„šæœ¬
python3 scripts/replay_task_lifecycle.py <task_id>
python3 scripts/replay_task_lifecycle.py <task_id> --detailed

# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/unit/test_replay_tool.py -v

# éªŒè¯å¾—åˆ†
# é¢„æœŸ: 99åˆ†
```

### A.4 P2-DéªŒè¯

```bash
# å®Œæ•´æµ‹è¯•å¥—ä»¶
pytest tests/unit/task -v
pytest tests/integration/task -v
pytest tests/performance/ -v

# æœ€ç»ˆè¦†ç›–ç‡
./scripts/coverage_scope_task.sh

# éªŒè¯å¾—åˆ†
# é¢„æœŸ: 100åˆ†
```

---

## é™„å½•B: é—®é¢˜æ’æŸ¥æŒ‡å—

### B.1 E2Eæµ‹è¯•å¤±è´¥

**ç—‡çŠ¶**: `sqlite3.OperationalError: no such table: tasks`

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥fixtureæ˜¯å¦æ­£ç¡®åˆå§‹åŒ–æ•°æ®åº“
2. æ£€æŸ¥schema SQLæ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥æ˜¯å¦æœ‰standalone BEGIN/COMMITè¯­å¥éœ€è¦è¿‡æ»¤
4. å‚è€ƒtest_event_service.pyçš„æˆåŠŸæ¡ˆä¾‹

### B.2 è¦†ç›–ç‡æœªæå‡

**ç—‡çŠ¶**: æ·»åŠ æµ‹è¯•åè¦†ç›–ç‡æ²¡æœ‰æ˜æ˜¾å˜åŒ–

**æ’æŸ¥æ­¥éª¤**:
1. ç¡®è®¤æµ‹è¯•å®é™…æ‰§è¡Œäº†ï¼ˆä¸æ˜¯è¢«skipï¼‰
2. æ£€æŸ¥æµ‹è¯•æ˜¯å¦çœŸæ­£è¦†ç›–äº†ç›®æ ‡ä»£ç è¡Œ
3. ä½¿ç”¨`--cov-report=html`æŸ¥çœ‹è¯¦ç»†è¦†ç›–æƒ…å†µ
4. ç¡®è®¤mockæ²¡æœ‰é˜»æ­¢ä»£ç æ‰§è¡Œ

### B.3 å›æ”¾è„šæœ¬é”™è¯¯

**ç—‡çŠ¶**: å›æ”¾è„šæœ¬æŠ›å‡ºå¼‚å¸¸

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥task_idæ˜¯å¦å­˜åœ¨
2. æ£€æŸ¥æ•°æ®åº“è·¯å¾„æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥APIæ˜¯å¦æœ‰breaking changes
4. ä½¿ç”¨`--help`æŸ¥çœ‹ç”¨æ³•

---

## é™„å½•C: æ—¶é—´åˆ†é…å»ºè®®

### C.1 æœ€å°å¯è¡Œè·¯å¾„ï¼ˆ95åˆ†ï¼‰

**æ€»å·¥æ—¶**: 1.5å°æ—¶
- P2-A: 1.5h â†’ 95åˆ†

### C.2 æ¨èè·¯å¾„ï¼ˆ99åˆ†ï¼‰

**æ€»å·¥æ—¶**: 5.5å°æ—¶
- ç¬¬1å¤©: P2-A (1.5h) â†’ 95åˆ†
- ç¬¬2å¤©: P2-B (3.0h) || P2-C (1.0h) â†’ 99åˆ†

### C.3 å®Œæ•´è·¯å¾„ï¼ˆ100åˆ†ï¼‰

**æ€»å·¥æ—¶**: 7.5å°æ—¶
- ç¬¬1å¤©: P2-A (1.5h) â†’ 95åˆ†
- ç¬¬2å¤©: P2-B (3.0h) || P2-C (1.0h) â†’ 99åˆ†
- ç¬¬3å¤©: P2-D (2.0h) â†’ 100åˆ†

---

## ç»“è®º

æœ¬æ–‡æ¡£æä¾›äº†P2é˜¶æ®µä»89åˆ†åˆ°100åˆ†çš„è¯¦ç»†å®æ–½æŒ‡å—ï¼ŒåŒ…æ‹¬ï¼š

- 4ä¸ªå¹¶è¡Œä»»åŠ¡çš„è¯¦ç»†æ­¥éª¤
- æ¯ä¸ªå­ä»»åŠ¡çš„ä»£ç ç¤ºä¾‹
- å®Œæ•´çš„éªŒæ”¶æ ‡å‡†
- é—®é¢˜æ’æŸ¥æŒ‡å—
- æ—¶é—´åˆ†é…å»ºè®®

**æ¨èæ‰§è¡Œé¡ºåº**:
1. ç«‹å³å¯åŠ¨P2-Aï¼ˆE2Eç¯å¢ƒä¿®å¤ï¼‰â†’ å¿«é€Ÿè¾¾æˆ95åˆ†
2. å¹¶è¡Œæ‰§è¡ŒP2-Bå’ŒP2-C â†’ è¾¾æˆ99åˆ†
3. å†²åˆºP2-D â†’ è¾¾æˆ100åˆ†æ»¡åˆ†

**æ‰€æœ‰ä»»åŠ¡å‡å¯ç‹¬ç«‹æ‰§è¡Œï¼Œæ— å¤–éƒ¨ä¾èµ–ï¼Œé£é™©å¯æ§ã€‚**

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2026-01-30
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**ä¸‹ä¸€æ­¥**: å¼€å§‹æ‰§è¡ŒP2-Aä»»åŠ¡
