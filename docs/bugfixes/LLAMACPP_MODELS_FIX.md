# LlamaCpp Models API ä¿®å¤

## ğŸ› é—®é¢˜æè¿°

**ç”¨æˆ·æŠ¥å‘Šçš„çŸ›ç›¾ç°è±¡**:
- âœ… Providers é¡µé¢æ˜¾ç¤º llama.cpp æœ‰ 3 ä¸ªå®ä¾‹ï¼ˆglm47flash-q8, qwen3-coder-30b, qwen2.5-coder-7bï¼‰
- âŒ Chat é¡µé¢é€‰æ‹© llama.cpp provider æ—¶æ˜¾ç¤º "Provider not available"
- âŒ API è°ƒç”¨ `/api/providers/llamacpp/models` è¿”å› 404

---

## ğŸ” æ ¹æœ¬åŸå› 

### æ¶æ„ä¸åŒ¹é…

#### 1. **é™æ€ Provider åˆ—è¡¨ vs åŠ¨æ€ Provider æ³¨å†Œ**

**`GET /api/providers`** (line 140-188):
- è¿”å›**ç¡¬ç¼–ç çš„é™æ€åˆ—è¡¨**
- åŒ…å« `{id: "llamacpp", label: "llama.cpp"}`
- ä¸ä¾èµ– ProviderRegistry

```python
return ProvidersListResponse(
    local=[
        ProviderInfo(id="llamacpp", label="llama.cpp", ...),
        # ... other providers
    ]
)
```

#### 2. **ProviderRegistry ä¸­çš„å®é™…æ³¨å†Œ**

ProviderRegistry ä¸­å®é™…æ³¨å†Œçš„æ˜¯**å®ä¾‹çº§åˆ«çš„ providers**:
- `llamacpp:glm47flash-q8`
- `llamacpp:qwen3-coder-30b`
- `llamacpp:qwen2.5-coder-7b`

**æ²¡æœ‰**æ³¨å†Œé¡¶å±‚çš„ `llamacpp` providerã€‚

#### 3. **Models API çš„æŸ¥è¯¢é€»è¾‘**

**`GET /api/providers/{provider_id}/models`** (line 233-264):
- ä» ProviderRegistry è·å– provider
- è°ƒç”¨ `registry.get("llamacpp")`
- è¿”å› `None`ï¼ˆå› ä¸ºåªæœ‰ `llamacpp:*` å®ä¾‹ï¼‰
- æŠ›å‡º 404 é”™è¯¯

```python
provider = registry.get(provider_id)  # æŸ¥æ‰¾ "llamacpp"
if not provider:
    raise HTTPException(status_code=404)  # âŒ æ‰¾ä¸åˆ°
```

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

### å®ç° Provider ç±»å‹èšåˆæŸ¥è¯¢

å½“æŸ¥è¯¢ `llamacpp` æ—¶ï¼Œè‡ªåŠ¨èšåˆæ‰€æœ‰ `llamacpp:*` å®ä¾‹çš„ modelsã€‚

### ä¿®æ”¹çš„æ–‡ä»¶

**agentos/webui/api/providers.py** (line 233-305)

### ä¿®å¤é€»è¾‘

```python
@router.get("/{provider_id}/models")
async def get_provider_models(provider_id: str) -> ModelsListResponse:
    registry = ProviderRegistry.get_instance()

    # Step 1: å°è¯•è·å–ç²¾ç¡®åŒ¹é…çš„ provider
    provider = registry.get(provider_id)

    if provider:
        # å•ä¸ª providerï¼Œç›´æ¥è¿”å›å…¶ models
        models = await provider.list_models()
        return ModelsListResponse(provider_id=provider_id, models=[...])
    else:
        # Step 2: æ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰å‰ç¼€åŒ¹é…çš„å®ä¾‹
        # ä¾‹å¦‚: "llamacpp" -> ["llamacpp:qwen3-coder-30b", "llamacpp:qwen2.5-coder-7b"]
        all_providers = registry.list_all()
        prefix = f"{provider_id}:"
        matching_providers = [p for p in all_providers if p.id.startswith(prefix)]

        if not matching_providers:
            raise HTTPException(status_code=404)

        # Step 3: èšåˆæ‰€æœ‰åŒ¹é…å®ä¾‹çš„ models
        all_models = []
        seen_model_ids = set()

        for provider in matching_providers:
            try:
                models = await provider.list_models()
                for model in models:
                    # å»é‡
                    if model.id not in seen_model_ids:
                        all_models.append(ModelInfoResponse(...))
                        seen_model_ids.add(model.id)
            except Exception as e:
                # å®¹é”™ï¼šå•ä¸ªå®ä¾‹å¤±è´¥ä¸å½±å“å…¶ä»–å®ä¾‹
                print(f"Warning: Failed to list models from {provider.id}: {e}")
                continue

        return ModelsListResponse(provider_id=provider_id, models=all_models)
```

### å…³é”®ç‰¹æ€§

1. **å‘åå…¼å®¹**:
   - ä»ç„¶æ”¯æŒæŸ¥è¯¢å…·ä½“å®ä¾‹ï¼ˆå¦‚ `llamacpp:qwen3-coder-30b`ï¼‰
   - æ–°å¢æ”¯æŒæŸ¥è¯¢ provider ç±»å‹ï¼ˆå¦‚ `llamacpp`ï¼‰

2. **è‡ªåŠ¨èšåˆ**:
   - æŸ¥è¯¢ `llamacpp` æ—¶ï¼Œè‡ªåŠ¨æ‰¾åˆ°æ‰€æœ‰ `llamacpp:*` å®ä¾‹
   - èšåˆæ‰€æœ‰å®ä¾‹çš„ models
   - è‡ªåŠ¨å»é‡ï¼ˆåŸºäº model.idï¼‰

3. **å®¹é”™å¤„ç†**:
   - å•ä¸ªå®ä¾‹å¤±è´¥ä¸å½±å“å…¶ä»–å®ä¾‹
   - ä½¿ç”¨ `try-except` æ•è·å¼‚å¸¸
   - è®°å½•è­¦å‘Šä½†ç»§ç»­å¤„ç†

---

## ğŸ§ª éªŒè¯ç»“æœ

### Before (ä¿®å¤å‰)

```bash
$ curl 'http://127.0.0.1:8080/api/providers/llamacpp/models'
{"detail":"Provider 'llamacpp' not found"}
```

### After (ä¿®å¤å)

```bash
$ curl 'http://127.0.0.1:8080/api/providers/llamacpp/models'
{
    "provider_id": "llamacpp",
    "models": [
        {
            "id": "Qwen3-Coder-30B-A3B-Instruct-UD-Q8_K_XL.gguf",
            "label": "Qwen3-Coder-30B-A3B-Instruct-UD-Q8_K_XL.gguf",
            "context_window": null
        },
        {
            "id": "qwen2.5-coder-7b-instruct-q8_0.gguf",
            "label": "qwen2.5-coder-7b-instruct-q8_0.gguf",
            "context_window": null
        }
    ]
}
```

âœ… æˆåŠŸè¿”å› 2 ä¸ª modelsï¼ˆæ¥è‡ª 2 ä¸ªå¯ç”¨çš„ llamacpp å®ä¾‹ï¼‰

---

## ğŸ”§ å…¶ä»–ä¿®å¤

### ä¿®å¤ ProviderRegistry æ–¹æ³•è°ƒç”¨

**é”™è¯¯**: ä½¿ç”¨äº†ä¸å­˜åœ¨çš„ `registry.list()` æ–¹æ³•

**ä¿®å¤**: æ”¹ä¸ºæ­£ç¡®çš„ `registry.list_all()` æ–¹æ³•

```python
# ä¿®å¤å‰
all_providers = registry.list()  # âŒ æ–¹æ³•ä¸å­˜åœ¨

# ä¿®å¤å
all_providers = registry.list_all()  # âœ… æ­£ç¡®æ–¹æ³•
```

---

## ğŸ“Š å·¥ä½œåŸç†

### Provider å®ä¾‹ç»“æ„

```
ProviderRegistry
â”œâ”€â”€ ollama (å•å®ä¾‹)
â”œâ”€â”€ lmstudio (å•å®ä¾‹)
â”œâ”€â”€ llamacpp:glm47flash-q8 (å®ä¾‹ 1)
â”œâ”€â”€ llamacpp:qwen3-coder-30b (å®ä¾‹ 2)
â””â”€â”€ llamacpp:qwen2.5-coder-7b (å®ä¾‹ 3)
```

### API æŸ¥è¯¢è¡Œä¸º

| æŸ¥è¯¢ | è¡Œä¸º | ç»“æœ |
|------|------|------|
| `ollama` | ç²¾ç¡®åŒ¹é… | è¿”å› ollama çš„ models |
| `llamacpp` | å‰ç¼€åŒ¹é… | èšåˆæ‰€æœ‰ `llamacpp:*` çš„ models |
| `llamacpp:qwen3-coder-30b` | ç²¾ç¡®åŒ¹é… | è¿”å›è¯¥å®ä¾‹çš„ models |

### èšåˆé€»è¾‘ç¤ºä¾‹

```
æŸ¥è¯¢: /api/providers/llamacpp/models

Step 1: registry.get("llamacpp") â†’ None (ä¸å­˜åœ¨)

Step 2: æŸ¥æ‰¾å‰ç¼€åŒ¹é…
  - llamacpp:glm47flash-q8 âŒ (ERROR, æœåŠ¡æœªè¿è¡Œ)
  - llamacpp:qwen3-coder-30b âœ… (READY)
  - llamacpp:qwen2.5-coder-7b âœ… (READY)

Step 3: èšåˆ models
  - qwen3-coder-30b â†’ [Qwen3-Coder-30B-A3B-Instruct-UD-Q8_K_XL.gguf]
  - qwen2.5-coder-7b â†’ [qwen2.5-coder-7b-instruct-q8_0.gguf]

Step 4: å»é‡å¹¶è¿”å›
  - 2 ä¸ª models
```

---

## ğŸ¯ ç”¨æˆ·ä½“éªŒæ”¹è¿›

### Before (ä¿®å¤å‰)

```
Chat é¡µé¢ â†’ é€‰æ‹© llama.cpp â†’ Provider not available âŒ
```

### After (ä¿®å¤å)

```
Chat é¡µé¢ â†’ é€‰æ‹© llama.cpp â†’ æ˜¾ç¤º 2 ä¸ªå¯ç”¨ models âœ…
  - Qwen3-Coder-30B-A3B-Instruct-UD-Q8_K_XL.gguf
  - qwen2.5-coder-7b-instruct-q8_0.gguf
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. é‡å¯æœåŠ¡å™¨

```bash
./quick_restart.sh
```

### 2. æ¸…é™¤æµè§ˆå™¨ç¼“å­˜

```bash
# Chrome/Edge: å¼€å‘è€…å·¥å…· â†’ å³é”®åˆ·æ–°æŒ‰é’® â†’ æ¸…ç©ºç¼“å­˜å¹¶ç¡¬åˆ·æ–°
Cmd+Shift+R (Mac)
Ctrl+Shift+R (Windows/Linux)
```

### 3. æµ‹è¯• Chat é¡µé¢

1. è®¿é—® http://127.0.0.1:8080
2. åœ¨ Chat é¡µé¢é€‰æ‹© Provider: `llama.cpp`
3. âœ… åº”è¯¥æ˜¾ç¤ºå¯ç”¨çš„ models
4. âœ… å¯ä»¥é€‰æ‹© model å¹¶å¼€å§‹å¯¹è¯

---

## ğŸ“‹ æŠ€æœ¯ç»†èŠ‚

### ProviderRegistry å¯ç”¨æ–¹æ³•

| æ–¹æ³• | æè¿° |
|------|------|
| `get_instance()` | è·å–å•ä¾‹å®ä¾‹ |
| `register(provider)` | æ³¨å†Œ provider |
| `get(provider_id)` | è·å–å•ä¸ª provider |
| `list_all()` | è·å–æ‰€æœ‰ providers |
| `get_all_status()` | è·å–æ‰€æœ‰ provider çŠ¶æ€ |

### Provider ID å‘½åè§„èŒƒ

| ç±»å‹ | æ ¼å¼ | ç¤ºä¾‹ |
|------|------|------|
| å•å®ä¾‹ Provider | `provider_name` | `ollama`, `lmstudio` |
| å¤šå®ä¾‹ Provider | `provider_name:instance_name` | `llamacpp:qwen3-coder-30b` |

---

## âœ… éªŒæ”¶æ¸…å•

- [x] `/api/providers/llamacpp/models` è¿”å› 200
- [x] è¿”å›çš„ models æ¥è‡ªæ‰€æœ‰å¯ç”¨çš„ llamacpp å®ä¾‹
- [x] è‡ªåŠ¨å»é‡ç›¸åŒçš„ model ID
- [x] å•ä¸ªå®ä¾‹å¤±è´¥ä¸å½±å“æ•´ä½“ç»“æœ
- [x] Chat é¡µé¢å¯ä»¥æ­£å¸¸é€‰æ‹© llama.cpp provider
- [x] Chat é¡µé¢å¯ä»¥çœ‹åˆ°å¯ç”¨çš„ models
- [ ] æµè§ˆå™¨ç¼“å­˜å·²æ¸…é™¤
- [ ] ç”¨æˆ·éªŒè¯åŠŸèƒ½æ­£å¸¸

---

**ä¿®å¤å®Œæˆæ—¶é—´**: 2026-01-28
**æœåŠ¡å™¨çŠ¶æ€**: âœ… è¿è¡Œä¸­
**API æµ‹è¯•**: âœ… é€šè¿‡
