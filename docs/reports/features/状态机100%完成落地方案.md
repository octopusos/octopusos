# ğŸ¯ çŠ¶æ€æœº 100% å®Œæˆè½åœ°æ–¹æ¡ˆ

**ç›®æ ‡**: å°†çŠ¶æ€æœºå®Œæˆåº¦ä» 70% æå‡åˆ° 100%
**é¢„è®¡å·¥æœŸ**: 10 å·¥ä½œæ—¥
**è´Ÿè´£äºº**: [å¾…å®š]
**å¼€å§‹æ—¥æœŸ**: [å¾…å®š]

---

## ğŸ“‹ ç›®å½•

1. [æ•´ä½“æ¶æ„](#æ•´ä½“æ¶æ„)
2. [Phase 1: Retry ç­–ç•¥ç³»ç»Ÿ](#phase-1-retry-ç­–ç•¥ç³»ç»Ÿ)
3. [Phase 2: Timeout æœºåˆ¶](#phase-2-timeout-æœºåˆ¶)
4. [Phase 3: Cancel è¿è¡Œä»»åŠ¡](#phase-3-cancel-è¿è¡Œä»»åŠ¡)
5. [Phase 4: æµ‹è¯•å®Œå–„](#phase-4-æµ‹è¯•å®Œå–„)
6. [Phase 5: æ–‡æ¡£å®Œå–„](#phase-5-æ–‡æ¡£å®Œå–„)
7. [éªŒæ”¶æ ‡å‡†](#éªŒæ”¶æ ‡å‡†)
8. [é£é™©è¯„ä¼°](#é£é™©è¯„ä¼°)

---

## æ•´ä½“æ¶æ„

### æ–°å¢/ä¿®æ”¹æ–‡ä»¶æ¸…å•

```
agentos/core/task/
â”œâ”€â”€ models.py                      # [ä¿®æ”¹] æ·»åŠ  retry/timeout å…ƒæ•°æ®æ¨¡å‹
â”œâ”€â”€ retry_strategy.py              # [æ–°å¢] Retry ç­–ç•¥é…ç½®å’Œé€»è¾‘
â”œâ”€â”€ timeout_manager.py             # [æ–°å¢] Timeout ç®¡ç†å™¨
â”œâ”€â”€ cancel_handler.py              # [æ–°å¢] Cancel å¤„ç†å™¨
â”œâ”€â”€ service.py                     # [ä¿®æ”¹] é›†æˆ retry/timeout/cancel
â””â”€â”€ state_machine.py               # [ä¿®æ”¹] æ·»åŠ  retry è½¬æ¢è§„åˆ™

agentos/core/runner/
â””â”€â”€ task_runner.py                 # [ä¿®æ”¹] é›†æˆæ‰€æœ‰æ–°æœºåˆ¶

tests/unit/task/
â”œâ”€â”€ test_retry_strategy.py         # [æ–°å¢] Retry ç­–ç•¥æµ‹è¯•
â”œâ”€â”€ test_timeout_manager.py        # [æ–°å¢] Timeout æµ‹è¯•
â”œâ”€â”€ test_cancel_handler.py         # [æ–°å¢] Cancel æµ‹è¯•
â””â”€â”€ test_state_machine_complete.py # [æ–°å¢] å®Œæ•´çŠ¶æ€æœºæµ‹è¯•

tests/integration/task/
â”œâ”€â”€ test_retry_e2e.py              # [æ–°å¢] Retry ç«¯åˆ°ç«¯æµ‹è¯•
â”œâ”€â”€ test_timeout_e2e.py            # [æ–°å¢] Timeout ç«¯åˆ°ç«¯æµ‹è¯•
â””â”€â”€ test_cancel_running_e2e.py     # [æ–°å¢] Cancel Running ç«¯åˆ°ç«¯æµ‹è¯•

docs/task/
â”œâ”€â”€ RETRY_STRATEGY_GUIDE.md        # [æ–°å¢] Retry ç­–ç•¥æŒ‡å—
â”œâ”€â”€ TIMEOUT_CONFIGURATION.md       # [æ–°å¢] Timeout é…ç½®æŒ‡å—
â”œâ”€â”€ CANCEL_OPERATIONS.md           # [æ–°å¢] Cancel æ“ä½œæ‰‹å†Œ
â””â”€â”€ STATE_MACHINE_OPERATIONS.md    # [æ–°å¢] çŠ¶æ€æœºè¿ç»´æ‰‹å†Œ
```

---

## Phase 1: Retry ç­–ç•¥ç³»ç»Ÿ

**å·¥æœŸ**: 3 å¤©
**ç›®æ ‡**: Task çº§åˆ«çš„ Retry ç­–ç•¥é…ç½®å’Œé™åˆ¶

### 1.1 æ–°å¢ RetryStrategy æ¨¡å—

**æ–‡ä»¶**: `agentos/core/task/retry_strategy.py`

```python
"""
Task Retry Strategy

Provides task-level retry configuration and enforcement.
Distinct from tool-level retry (agentos/ext/tools/retry_policy.py).

Key Features:
1. Retry count limiting (prevent infinite retry)
2. Retry backoff configuration
3. Retry history tracking
4. Retry loop detection
"""

from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any
from datetime import datetime, timezone
from enum import Enum
import logging

logger = logging.getLogger(__name__)


class RetryBackoffType(str, Enum):
    """Retry backoff strategies."""
    NONE = "none"                    # No delay between retries
    FIXED = "fixed"                  # Fixed delay (e.g., 60s)
    LINEAR = "linear"                # Linear increase (60s, 120s, 180s)
    EXPONENTIAL = "exponential"      # Exponential backoff (60s, 120s, 240s)


@dataclass
class RetryConfig:
    """
    Task Retry Configuration

    Controls how many times a failed task can be retried and
    the delay between retry attempts.

    Attributes:
        max_retries: Maximum number of retries (default: 3)
        backoff_type: Retry backoff strategy
        base_delay_seconds: Base delay for backoff calculation (default: 60)
        max_delay_seconds: Maximum delay between retries (default: 3600)
    """
    max_retries: int = 3
    backoff_type: RetryBackoffType = RetryBackoffType.EXPONENTIAL
    base_delay_seconds: int = 60
    max_delay_seconds: int = 3600

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for metadata storage."""
        return {
            "max_retries": self.max_retries,
            "backoff_type": self.backoff_type.value,
            "base_delay_seconds": self.base_delay_seconds,
            "max_delay_seconds": self.max_delay_seconds,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "RetryConfig":
        """Create from dictionary."""
        return cls(
            max_retries=data.get("max_retries", 3),
            backoff_type=RetryBackoffType(data.get("backoff_type", "exponential")),
            base_delay_seconds=data.get("base_delay_seconds", 60),
            max_delay_seconds=data.get("max_delay_seconds", 3600),
        )


@dataclass
class RetryState:
    """
    Current retry state for a task

    Tracks retry attempts and calculates next retry time.

    Attributes:
        retry_count: Number of retry attempts so far
        last_retry_at: Timestamp of last retry attempt
        retry_history: List of retry timestamps with reasons
        next_retry_after: Calculated next retry time (ISO 8601)
    """
    retry_count: int = 0
    last_retry_at: Optional[str] = None
    retry_history: List[Dict[str, Any]] = field(default_factory=list)
    next_retry_after: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for metadata storage."""
        return {
            "retry_count": self.retry_count,
            "last_retry_at": self.last_retry_at,
            "retry_history": self.retry_history,
            "next_retry_after": self.next_retry_after,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "RetryState":
        """Create from dictionary."""
        return cls(
            retry_count=data.get("retry_count", 0),
            last_retry_at=data.get("last_retry_at"),
            retry_history=data.get("retry_history", []),
            next_retry_after=data.get("next_retry_after"),
        )


class RetryStrategyManager:
    """
    Retry Strategy Manager

    Enforces retry policies and prevents infinite retry loops.
    """

    def can_retry(
        self,
        retry_config: RetryConfig,
        retry_state: RetryState
    ) -> tuple[bool, Optional[str]]:
        """
        Check if a task can be retried

        Args:
            retry_config: Retry configuration
            retry_state: Current retry state

        Returns:
            (can_retry, reason) tuple
        """
        # Check retry count limit
        if retry_state.retry_count >= retry_config.max_retries:
            return False, f"Max retries ({retry_config.max_retries}) exceeded"

        # Check for retry loops (same failure repeated 3+ times)
        if len(retry_state.retry_history) >= 3:
            recent_reasons = [
                h.get("reason", "")
                for h in retry_state.retry_history[-3:]
            ]
            if len(set(recent_reasons)) == 1:
                return False, f"Retry loop detected: same failure repeated 3 times"

        return True, None

    def calculate_next_retry_time(
        self,
        retry_config: RetryConfig,
        retry_state: RetryState
    ) -> str:
        """
        Calculate next retry time based on backoff strategy

        Args:
            retry_config: Retry configuration
            retry_state: Current retry state

        Returns:
            ISO 8601 timestamp for next retry
        """
        import math
        from datetime import timedelta

        # Calculate delay based on backoff type
        if retry_config.backoff_type == RetryBackoffType.NONE:
            delay_seconds = 0
        elif retry_config.backoff_type == RetryBackoffType.FIXED:
            delay_seconds = retry_config.base_delay_seconds
        elif retry_config.backoff_type == RetryBackoffType.LINEAR:
            delay_seconds = retry_config.base_delay_seconds * (retry_state.retry_count + 1)
        else:  # EXPONENTIAL
            delay_seconds = retry_config.base_delay_seconds * (2 ** retry_state.retry_count)

        # Cap at max delay
        delay_seconds = min(delay_seconds, retry_config.max_delay_seconds)

        # Calculate next retry time
        now = datetime.now(timezone.utc)
        next_retry = now + timedelta(seconds=delay_seconds)

        return next_retry.isoformat()

    def record_retry_attempt(
        self,
        retry_state: RetryState,
        reason: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> RetryState:
        """
        Record a retry attempt

        Args:
            retry_state: Current retry state
            reason: Reason for retry
            metadata: Optional metadata

        Returns:
            Updated retry state
        """
        now = datetime.now(timezone.utc).isoformat()

        # Increment retry count
        retry_state.retry_count += 1
        retry_state.last_retry_at = now

        # Add to history
        retry_state.retry_history.append({
            "attempt": retry_state.retry_count,
            "timestamp": now,
            "reason": reason,
            "metadata": metadata or {},
        })

        return retry_state

    def get_retry_metrics(self, retry_state: RetryState) -> Dict[str, Any]:
        """
        Get retry metrics for observability

        Args:
            retry_state: Current retry state

        Returns:
            Dictionary with retry metrics
        """
        return {
            "retry_count": retry_state.retry_count,
            "last_retry_at": retry_state.last_retry_at,
            "retry_attempts": len(retry_state.retry_history),
            "retry_reasons": [h.get("reason") for h in retry_state.retry_history],
        }
```

### 1.2 ä¿®æ”¹ Task æ¨¡å‹

**æ–‡ä»¶**: `agentos/core/task/models.py`

```python
# åœ¨ Task ç±»ä¸­æ·»åŠ æ–¹æ³•

def get_retry_config(self) -> "RetryConfig":
    """Get retry configuration from metadata"""
    from agentos.core.task.retry_strategy import RetryConfig

    retry_data = self.metadata.get("retry_config")
    if retry_data:
        return RetryConfig.from_dict(retry_data)
    else:
        # Return default config
        return RetryConfig()

def get_retry_state(self) -> "RetryState":
    """Get retry state from metadata"""
    from agentos.core.task.retry_strategy import RetryState

    retry_state_data = self.metadata.get("retry_state")
    if retry_state_data:
        return RetryState.from_dict(retry_state_data)
    else:
        # Return initial state
        return RetryState()

def update_retry_state(self, retry_state: "RetryState") -> None:
    """Update retry state in metadata"""
    self.metadata["retry_state"] = retry_state.to_dict()
```

### 1.3 ä¿®æ”¹ TaskService

**æ–‡ä»¶**: `agentos/core/task/service.py`

```python
# ä¿®æ”¹ retry_failed_task æ–¹æ³•

def retry_failed_task(
    self,
    task_id: str,
    actor: str,
    reason: str = "Task queued for retry",
    metadata: Optional[Dict[str, Any]] = None
) -> Task:
    """
    Retry a failed task

    Enforces retry policy:
    1. Check if retry is allowed (max_retries not exceeded)
    2. Check for retry loops
    3. Update retry state
    4. Transition to QUEUED state

    Transition: FAILED -> QUEUED

    Args:
        task_id: Task ID
        actor: Who is retrying the task
        reason: Reason for retry
        metadata: Optional metadata for the transition

    Returns:
        Updated task in QUEUED state

    Raises:
        InvalidTransitionError: If task is not in FAILED state
        RetryNotAllowedError: If retry is not allowed (max retries exceeded or retry loop)
    """
    from agentos.core.task.retry_strategy import RetryStrategyManager
    from agentos.core.task.errors import RetryNotAllowedError

    # Load task
    task = self.get_task(task_id)
    if not task:
        raise TaskNotFoundError(task_id)

    # Get retry config and state
    retry_config = task.get_retry_config()
    retry_state = task.get_retry_state()

    # Check if retry is allowed
    retry_manager = RetryStrategyManager()
    can_retry, retry_reason = retry_manager.can_retry(retry_config, retry_state)

    if not can_retry:
        raise RetryNotAllowedError(
            task_id=task_id,
            current_state=task.status,
            reason=retry_reason
        )

    # Record retry attempt
    retry_state = retry_manager.record_retry_attempt(
        retry_state,
        reason=reason,
        metadata=metadata
    )

    # Calculate next retry time
    next_retry_time = retry_manager.calculate_next_retry_time(
        retry_config,
        retry_state
    )
    retry_state.next_retry_after = next_retry_time

    # Update task metadata
    task.update_retry_state(retry_state)
    self.task_manager.update_task(task)

    # Record audit
    self.add_audit(
        task_id=task_id,
        event_type="TASK_RETRY_ATTEMPT",
        level="info",
        payload={
            "retry_count": retry_state.retry_count,
            "max_retries": retry_config.max_retries,
            "next_retry_after": next_retry_time,
            "reason": reason,
        }
    )

    # Perform state transition
    return self.state_machine.transition(
        task_id=task_id,
        to=TaskState.QUEUED.value,
        actor=actor,
        reason=f"Retry attempt {retry_state.retry_count}/{retry_config.max_retries}: {reason}",
        metadata=metadata
    )
```

### 1.4 æµ‹è¯•æ–‡ä»¶

**æ–‡ä»¶**: `tests/unit/task/test_retry_strategy.py`

```python
"""
Unit Tests: Retry Strategy

Tests retry configuration, retry count limiting, and retry loop detection.
"""

import pytest
from datetime import datetime, timezone, timedelta

from agentos.core.task.retry_strategy import (
    RetryConfig,
    RetryState,
    RetryStrategyManager,
    RetryBackoffType,
)


def test_retry_config_default():
    """Test default retry configuration"""
    config = RetryConfig()
    assert config.max_retries == 3
    assert config.backoff_type == RetryBackoffType.EXPONENTIAL
    assert config.base_delay_seconds == 60


def test_retry_config_to_from_dict():
    """Test retry config serialization"""
    config = RetryConfig(
        max_retries=5,
        backoff_type=RetryBackoffType.LINEAR,
        base_delay_seconds=120,
    )

    data = config.to_dict()
    restored = RetryConfig.from_dict(data)

    assert restored.max_retries == 5
    assert restored.backoff_type == RetryBackoffType.LINEAR
    assert restored.base_delay_seconds == 120


def test_retry_state_initial():
    """Test initial retry state"""
    state = RetryState()
    assert state.retry_count == 0
    assert state.last_retry_at is None
    assert len(state.retry_history) == 0


def test_can_retry_within_limit():
    """Test retry allowed within max retries"""
    config = RetryConfig(max_retries=3)
    state = RetryState(retry_count=2)

    manager = RetryStrategyManager()
    can_retry, reason = manager.can_retry(config, state)

    assert can_retry is True
    assert reason is None


def test_can_retry_exceeded_limit():
    """Test retry denied when max retries exceeded"""
    config = RetryConfig(max_retries=3)
    state = RetryState(retry_count=3)

    manager = RetryStrategyManager()
    can_retry, reason = manager.can_retry(config, state)

    assert can_retry is False
    assert "Max retries" in reason


def test_can_retry_loop_detection():
    """Test retry loop detection (same failure 3+ times)"""
    config = RetryConfig(max_retries=10)
    state = RetryState(
        retry_count=3,
        retry_history=[
            {"reason": "gate_failed", "timestamp": "2026-01-29T10:00:00Z"},
            {"reason": "gate_failed", "timestamp": "2026-01-29T10:01:00Z"},
            {"reason": "gate_failed", "timestamp": "2026-01-29T10:02:00Z"},
        ]
    )

    manager = RetryStrategyManager()
    can_retry, reason = manager.can_retry(config, state)

    assert can_retry is False
    assert "Retry loop detected" in reason


def test_calculate_next_retry_time_exponential():
    """Test exponential backoff calculation"""
    config = RetryConfig(
        backoff_type=RetryBackoffType.EXPONENTIAL,
        base_delay_seconds=60,
    )
    state = RetryState(retry_count=2)  # 3rd retry

    manager = RetryStrategyManager()
    next_time_str = manager.calculate_next_retry_time(config, state)

    # Parse time
    next_time = datetime.fromisoformat(next_time_str)
    now = datetime.now(timezone.utc)

    # Should be ~240 seconds from now (60 * 2^2)
    delta = (next_time - now).total_seconds()
    assert 230 <= delta <= 250


def test_calculate_next_retry_time_fixed():
    """Test fixed delay calculation"""
    config = RetryConfig(
        backoff_type=RetryBackoffType.FIXED,
        base_delay_seconds=120,
    )
    state = RetryState(retry_count=5)

    manager = RetryStrategyManager()
    next_time_str = manager.calculate_next_retry_time(config, state)

    next_time = datetime.fromisoformat(next_time_str)
    now = datetime.now(timezone.utc)

    # Should be ~120 seconds from now
    delta = (next_time - now).total_seconds()
    assert 115 <= delta <= 125


def test_record_retry_attempt():
    """Test recording retry attempt"""
    state = RetryState(retry_count=0)
    manager = RetryStrategyManager()

    updated_state = manager.record_retry_attempt(
        state,
        reason="gate_failed",
        metadata={"gate": "doctor"}
    )

    assert updated_state.retry_count == 1
    assert updated_state.last_retry_at is not None
    assert len(updated_state.retry_history) == 1
    assert updated_state.retry_history[0]["reason"] == "gate_failed"


def test_get_retry_metrics():
    """Test retry metrics extraction"""
    state = RetryState(
        retry_count=3,
        retry_history=[
            {"reason": "timeout", "timestamp": "2026-01-29T10:00:00Z"},
            {"reason": "gate_failed", "timestamp": "2026-01-29T10:05:00Z"},
            {"reason": "gate_failed", "timestamp": "2026-01-29T10:10:00Z"},
        ]
    )

    manager = RetryStrategyManager()
    metrics = manager.get_retry_metrics(state)

    assert metrics["retry_count"] == 3
    assert metrics["retry_attempts"] == 3
    assert len(metrics["retry_reasons"]) == 3
    assert metrics["retry_reasons"][0] == "timeout"
```

---

## Phase 2: Timeout æœºåˆ¶

**å·¥æœŸ**: 2 å¤©
**ç›®æ ‡**: åŸºäº wallclock æ—¶é—´çš„è¶…æ—¶æ£€æµ‹å’Œå¤„ç†

### 2.1 æ–°å¢ TimeoutManager æ¨¡å—

**æ–‡ä»¶**: `agentos/core/task/timeout_manager.py`

```python
"""
Task Timeout Manager

Provides wallclock-based timeout detection and handling.

Key Features:
1. Configurable timeout duration
2. Timeout detection in runner loop
3. Graceful timeout handling
4. Timeout audit logging
"""

from dataclasses import dataclass
from typing import Optional, Dict, Any
from datetime import datetime, timezone, timedelta
import logging

logger = logging.getLogger(__name__)


@dataclass
class TimeoutConfig:
    """
    Task Timeout Configuration

    Attributes:
        enabled: Whether timeout is enabled
        timeout_seconds: Timeout duration in seconds (default: 3600 = 1 hour)
        warning_threshold: Warn when execution time exceeds this ratio (default: 0.8)
    """
    enabled: bool = True
    timeout_seconds: int = 3600  # 1 hour
    warning_threshold: float = 0.8  # Warn at 80% of timeout

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for metadata storage."""
        return {
            "enabled": self.enabled,
            "timeout_seconds": self.timeout_seconds,
            "warning_threshold": self.warning_threshold,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TimeoutConfig":
        """Create from dictionary."""
        return cls(
            enabled=data.get("enabled", True),
            timeout_seconds=data.get("timeout_seconds", 3600),
            warning_threshold=data.get("warning_threshold", 0.8),
        )


@dataclass
class TimeoutState:
    """
    Current timeout state for a task

    Attributes:
        execution_start_time: When execution started (ISO 8601)
        last_heartbeat: Last heartbeat timestamp
        warning_issued: Whether timeout warning has been issued
    """
    execution_start_time: Optional[str] = None
    last_heartbeat: Optional[str] = None
    warning_issued: bool = False

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for metadata storage."""
        return {
            "execution_start_time": self.execution_start_time,
            "last_heartbeat": self.last_heartbeat,
            "warning_issued": self.warning_issued,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TimeoutState":
        """Create from dictionary."""
        return cls(
            execution_start_time=data.get("execution_start_time"),
            last_heartbeat=data.get("last_heartbeat"),
            warning_issued=data.get("warning_issued", False),
        )


class TimeoutManager:
    """
    Timeout Manager

    Detects and handles task execution timeouts.
    """

    def start_timeout_tracking(
        self,
        timeout_state: TimeoutState
    ) -> TimeoutState:
        """
        Start timeout tracking for a task

        Args:
            timeout_state: Current timeout state

        Returns:
            Updated timeout state with start time
        """
        now = datetime.now(timezone.utc).isoformat()
        timeout_state.execution_start_time = now
        timeout_state.last_heartbeat = now
        timeout_state.warning_issued = False

        logger.info(f"Started timeout tracking at {now}")
        return timeout_state

    def check_timeout(
        self,
        timeout_config: TimeoutConfig,
        timeout_state: TimeoutState
    ) -> tuple[bool, Optional[str], Optional[str]]:
        """
        Check if task execution has timed out

        Args:
            timeout_config: Timeout configuration
            timeout_state: Current timeout state

        Returns:
            (is_timeout, warning_message, timeout_message) tuple
        """
        if not timeout_config.enabled:
            return False, None, None

        if not timeout_state.execution_start_time:
            return False, None, None

        # Calculate elapsed time
        start_time = datetime.fromisoformat(timeout_state.execution_start_time)
        now = datetime.now(timezone.utc)
        elapsed_seconds = (now - start_time).total_seconds()

        # Check for timeout
        if elapsed_seconds >= timeout_config.timeout_seconds:
            message = (
                f"Task execution timed out after {elapsed_seconds:.0f}s "
                f"(limit: {timeout_config.timeout_seconds}s)"
            )
            return True, None, message

        # Check for warning threshold
        warning_threshold_seconds = timeout_config.timeout_seconds * timeout_config.warning_threshold

        if elapsed_seconds >= warning_threshold_seconds and not timeout_state.warning_issued:
            remaining = timeout_config.timeout_seconds - elapsed_seconds
            warning = (
                f"Task execution approaching timeout: {elapsed_seconds:.0f}s elapsed, "
                f"{remaining:.0f}s remaining (limit: {timeout_config.timeout_seconds}s)"
            )
            return False, warning, None

        return False, None, None

    def update_heartbeat(
        self,
        timeout_state: TimeoutState
    ) -> TimeoutState:
        """
        Update last heartbeat timestamp

        Args:
            timeout_state: Current timeout state

        Returns:
            Updated timeout state
        """
        timeout_state.last_heartbeat = datetime.now(timezone.utc).isoformat()
        return timeout_state

    def mark_warning_issued(
        self,
        timeout_state: TimeoutState
    ) -> TimeoutState:
        """
        Mark that timeout warning has been issued

        Args:
            timeout_state: Current timeout state

        Returns:
            Updated timeout state
        """
        timeout_state.warning_issued = True
        return timeout_state

    def get_timeout_metrics(
        self,
        timeout_state: TimeoutState
    ) -> Dict[str, Any]:
        """
        Get timeout metrics for observability

        Args:
            timeout_state: Current timeout state

        Returns:
            Dictionary with timeout metrics
        """
        if not timeout_state.execution_start_time:
            return {
                "execution_start_time": None,
                "elapsed_seconds": None,
                "last_heartbeat": None,
            }

        start_time = datetime.fromisoformat(timeout_state.execution_start_time)
        now = datetime.now(timezone.utc)
        elapsed_seconds = (now - start_time).total_seconds()

        return {
            "execution_start_time": timeout_state.execution_start_time,
            "elapsed_seconds": elapsed_seconds,
            "last_heartbeat": timeout_state.last_heartbeat,
            "warning_issued": timeout_state.warning_issued,
        }
```

### 2.2 ä¿®æ”¹ Task æ¨¡å‹

**æ–‡ä»¶**: `agentos/core/task/models.py`

```python
# åœ¨ Task ç±»ä¸­æ·»åŠ æ–¹æ³•

def get_timeout_config(self) -> "TimeoutConfig":
    """Get timeout configuration from metadata"""
    from agentos.core.task.timeout_manager import TimeoutConfig

    timeout_data = self.metadata.get("timeout_config")
    if timeout_data:
        return TimeoutConfig.from_dict(timeout_data)
    else:
        return TimeoutConfig()

def get_timeout_state(self) -> "TimeoutState":
    """Get timeout state from metadata"""
    from agentos.core.task.timeout_manager import TimeoutState

    timeout_state_data = self.metadata.get("timeout_state")
    if timeout_state_data:
        return TimeoutState.from_dict(timeout_state_data)
    else:
        return TimeoutState()

def update_timeout_state(self, timeout_state: "TimeoutState") -> None:
    """Update timeout state in metadata"""
    self.metadata["timeout_state"] = timeout_state.to_dict()
```

### 2.3 ä¿®æ”¹ TaskRunner

**æ–‡ä»¶**: `agentos/core/runner/task_runner.py`

```python
# åœ¨ run_task æ–¹æ³•å¼€å§‹å¤„æ·»åŠ  timeout tracking

def run_task(self, task_id: str, max_iterations: int = 100):
    """Run a task in the background

    Args:
        task_id: Task ID to run
        max_iterations: Maximum number of state transitions (safety)
    """
    import os
    from agentos.core.task.timeout_manager import TimeoutManager

    logger.info(f"Starting task runner for task {task_id}")

    # Initialize timeout manager
    timeout_manager = TimeoutManager()

    # Load task to check for project settings
    task = self.task_manager.get_task(task_id)
    if not task:
        logger.error(f"Task {task_id} not found")
        return

    # Start timeout tracking
    timeout_config = task.get_timeout_config()
    timeout_state = task.get_timeout_state()
    timeout_state = timeout_manager.start_timeout_tracking(timeout_state)
    task.update_timeout_state(timeout_state)
    self.task_manager.update_task(task)

    # ... existing code ...

    try:
        while iteration < max_iterations:
            iteration += 1

            # 1. Load task from DB
            try:
                task = self.task_manager.get_task(task_id)
            except Exception as e:
                logger.error(f"Failed to load task {task_id}: {e}")
                exit_reason = "fatal_error"
                self.task_manager.update_task_exit_reason(task_id, exit_reason, status="failed")
                self._log_audit(task_id, "error", f"Task load error: {str(e)}")
                break

            # 2. Check timeout
            timeout_config = task.get_timeout_config()
            timeout_state = task.get_timeout_state()
            is_timeout, warning_msg, timeout_msg = timeout_manager.check_timeout(
                timeout_config,
                timeout_state
            )

            if is_timeout:
                logger.error(f"Task {task_id} timed out: {timeout_msg}")
                exit_reason = "timeout"
                self.task_manager.update_task_exit_reason(task_id, exit_reason, status="failed")
                self._log_audit(task_id, "error", timeout_msg)
                break

            if warning_msg:
                logger.warning(f"Task {task_id} timeout warning: {warning_msg}")
                self._log_audit(task_id, "warn", warning_msg)
                timeout_state = timeout_manager.mark_warning_issued(timeout_state)
                task.update_timeout_state(timeout_state)
                self.task_manager.update_task(task)

            # Update heartbeat
            timeout_state = timeout_manager.update_heartbeat(timeout_state)
            task.update_timeout_state(timeout_state)

            # 3. Check if task is in terminal state
            # ... existing code ...
```

---

## Phase 3: Cancel è¿è¡Œä»»åŠ¡

**å·¥æœŸ**: 2 å¤©
**ç›®æ ‡**: æ”¯æŒå–æ¶ˆæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡

### 3.1 æ–°å¢ CancelHandler æ¨¡å—

**æ–‡ä»¶**: `agentos/core/task/cancel_handler.py`

```python
"""
Task Cancel Handler

Provides safe cancellation of running tasks.

Key Features:
1. Cancel signal detection
2. Graceful shutdown
3. Cleanup on cancel
4. Cancel audit logging
"""

import logging
from typing import Optional, Dict, Any
from datetime import datetime, timezone

logger = logging.getLogger(__name__)


class CancelHandler:
    """
    Cancel Handler

    Handles cancellation requests for running tasks.
    """

    def should_cancel(self, task_id: str, current_status: str) -> tuple[bool, Optional[str]]:
        """
        Check if task should be canceled

        Loads task from DB and checks if status has changed to CANCELED.

        Args:
            task_id: Task ID
            current_status: Current known status

        Returns:
            (should_cancel, reason) tuple
        """
        from agentos.core.task import TaskManager

        task_manager = TaskManager()
        task = task_manager.get_task(task_id)

        if not task:
            return False, None

        # Check if status changed to CANCELED
        if task.status == "canceled" and current_status != "canceled":
            reason = task.metadata.get("cancel_reason", "User requested cancellation")
            return True, reason

        return False, None

    def perform_cleanup(
        self,
        task_id: str,
        cleanup_actions: Optional[list[str]] = None
    ) -> Dict[str, Any]:
        """
        Perform cleanup actions before canceling

        Args:
            task_id: Task ID
            cleanup_actions: List of cleanup actions to perform

        Returns:
            Dictionary with cleanup results
        """
        results = {
            "task_id": task_id,
            "cleanup_performed": [],
            "cleanup_failed": [],
        }

        if not cleanup_actions:
            cleanup_actions = ["flush_logs", "release_resources"]

        for action in cleanup_actions:
            try:
                if action == "flush_logs":
                    # Flush any pending logs
                    logger.info(f"Flushing logs for task {task_id}")
                    results["cleanup_performed"].append("flush_logs")

                elif action == "release_resources":
                    # Release any held resources
                    logger.info(f"Releasing resources for task {task_id}")
                    results["cleanup_performed"].append("release_resources")

                elif action == "save_partial_results":
                    # Save any partial results
                    logger.info(f"Saving partial results for task {task_id}")
                    results["cleanup_performed"].append("save_partial_results")

            except Exception as e:
                logger.error(f"Cleanup action '{action}' failed for task {task_id}: {e}")
                results["cleanup_failed"].append({
                    "action": action,
                    "error": str(e)
                })

        return results

    def record_cancel_event(
        self,
        task_id: str,
        actor: str,
        reason: str,
        cleanup_results: Dict[str, Any]
    ) -> None:
        """
        Record cancel event in audit log

        Args:
            task_id: Task ID
            actor: Who canceled the task
            reason: Reason for cancellation
            cleanup_results: Results of cleanup operations
        """
        from agentos.core.task import TaskManager

        task_manager = TaskManager()
        task_manager.add_audit(
            task_id=task_id,
            event_type="TASK_CANCELED_DURING_EXECUTION",
            level="warn",
            payload={
                "actor": actor,
                "reason": reason,
                "cleanup_results": cleanup_results,
                "canceled_at": datetime.now(timezone.utc).isoformat(),
            }
        )

        logger.warning(f"Task {task_id} canceled by {actor}: {reason}")
```

### 3.2 ä¿®æ”¹ TaskRunner

**æ–‡ä»¶**: `agentos/core/runner/task_runner.py`

```python
# åœ¨ run_task æ–¹æ³•çš„ä¸»å¾ªç¯ä¸­æ·»åŠ  cancel æ£€æµ‹

def run_task(self, task_id: str, max_iterations: int = 100):
    """Run a task in the background"""

    # ... existing initialization code ...

    from agentos.core.task.cancel_handler import CancelHandler
    cancel_handler = CancelHandler()

    try:
        while iteration < max_iterations:
            iteration += 1

            # 1. Load task from DB
            # ... existing code ...

            # 2. Check timeout
            # ... existing code ...

            # 3. Check for cancel signal
            should_cancel, cancel_reason = cancel_handler.should_cancel(
                task_id,
                task.status
            )

            if should_cancel:
                logger.warning(f"Task {task_id} cancel requested: {cancel_reason}")

                # Perform cleanup
                cleanup_results = cancel_handler.perform_cleanup(
                    task_id,
                    cleanup_actions=["flush_logs", "release_resources", "save_partial_results"]
                )

                # Record cancel event
                cancel_handler.record_cancel_event(
                    task_id=task_id,
                    actor=task.metadata.get("cancel_actor", "unknown"),
                    reason=cancel_reason,
                    cleanup_results=cleanup_results
                )

                exit_reason = "user_cancelled"
                self.task_manager.update_task_exit_reason(task_id, exit_reason)
                break

            # 4. Check if task is in terminal state
            # ... existing code ...
```

### 3.3 ä¿®æ”¹ TaskService

**æ–‡ä»¶**: `agentos/core/task/service.py`

```python
# æ·»åŠ  cancel_running_task æ–¹æ³•

def cancel_running_task(
    self,
    task_id: str,
    actor: str,
    reason: str,
    metadata: Optional[Dict[str, Any]] = None
) -> Task:
    """
    Cancel a running task

    This sends a cancel signal to the running task. The runner will
    detect the signal on its next iteration and perform graceful shutdown.

    Transition: RUNNING -> CANCELED

    Args:
        task_id: Task ID
        actor: Who is canceling the task
        reason: Reason for cancellation (REQUIRED)
        metadata: Optional metadata for the transition

    Returns:
        Updated task in CANCELED state

    Raises:
        TaskNotFoundError: If task doesn't exist
        InvalidTransitionError: If task is not in RUNNING state
    """
    # Validate task exists and is in correct state
    task = self.get_task(task_id)
    if not task:
        raise TaskNotFoundError(task_id)

    if task.status != TaskState.RUNNING.value:
        raise InvalidTransitionError(
            from_state=task.status,
            to_state=TaskState.CANCELED.value,
            reason="Can only cancel tasks in RUNNING state"
        )

    # Add cancel metadata for runner to detect
    if not task.metadata:
        task.metadata = {}

    task.metadata["cancel_actor"] = actor
    task.metadata["cancel_reason"] = reason
    task.metadata["cancel_requested_at"] = datetime.now(timezone.utc).isoformat()

    # Update task metadata first (runner will detect this)
    self.task_manager.update_task(task)

    # Record audit
    self.add_audit(
        task_id=task_id,
        event_type="TASK_CANCEL_REQUESTED",
        level="warn",
        payload={
            "actor": actor,
            "reason": reason,
            "metadata": metadata or {},
        }
    )

    # Perform state transition
    return self.state_machine.transition(
        task_id=task_id,
        to=TaskState.CANCELED.value,
        actor=actor,
        reason=f"Running task canceled: {reason}",
        metadata=metadata
    )
```

---

## Phase 4: æµ‹è¯•å®Œå–„

**å·¥æœŸ**: 2 å¤©
**ç›®æ ‡**: å®Œæ•´çš„æµ‹è¯•è¦†ç›– (å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯•)

### 4.1 é›†æˆæµ‹è¯•æ–‡ä»¶æ¸…å•

```python
# tests/integration/task/test_retry_e2e.py
"""
Integration Tests: Retry End-to-End

Tests complete retry flow from failure to successful retry.
"""

def test_retry_within_limit():
    """Test retry succeeds within max_retries limit"""
    pass

def test_retry_exceeds_limit():
    """Test retry fails when max_retries exceeded"""
    pass

def test_retry_loop_detection():
    """Test retry loop prevents infinite retry"""
    pass

def test_retry_backoff_exponential():
    """Test exponential backoff between retries"""
    pass

# tests/integration/task/test_timeout_e2e.py
"""
Integration Tests: Timeout End-to-End

Tests complete timeout flow from start to timeout.
"""

def test_task_timeout_after_limit():
    """Test task fails with timeout after reaching time limit"""
    pass

def test_task_timeout_warning():
    """Test timeout warning issued at 80% threshold"""
    pass

def test_task_completes_before_timeout():
    """Test task completes successfully before timeout"""
    pass

# tests/integration/task/test_cancel_running_e2e.py
"""
Integration Tests: Cancel Running Task End-to-End

Tests canceling a running task.
"""

def test_cancel_running_task():
    """Test canceling a running task succeeds"""
    pass

def test_cancel_cleanup_performed():
    """Test cleanup actions performed on cancel"""
    pass

def test_cancel_audit_recorded():
    """Test cancel event recorded in audit log"""
    pass
```

### 4.2 æµ‹è¯•è¦†ç›–æ¸…å•

| åŠŸèƒ½æ¨¡å— | å•å…ƒæµ‹è¯• | é›†æˆæµ‹è¯• | è¦†ç›–ç‡ç›®æ ‡ |
|---------|---------|---------|----------|
| Retry Strategy | âœ… test_retry_strategy.py | âœ… test_retry_e2e.py | 90%+ |
| Timeout Manager | âœ… test_timeout_manager.py | âœ… test_timeout_e2e.py | 90%+ |
| Cancel Handler | âœ… test_cancel_handler.py | âœ… test_cancel_running_e2e.py | 90%+ |
| State Machine | âœ… test_state_machine_complete.py | âœ… test_e2e_workflow.py | 95%+ |

---

## Phase 5: æ–‡æ¡£å®Œå–„

**å·¥æœŸ**: 1 å¤©
**ç›®æ ‡**: å®Œæ•´çš„è¿ç»´æ–‡æ¡£å’Œé…ç½®æŒ‡å—

### 5.1 æ–‡æ¡£æ¸…å•

#### 5.1.1 Retry ç­–ç•¥æŒ‡å—

**æ–‡ä»¶**: `docs/task/RETRY_STRATEGY_GUIDE.md`

å†…å®¹å¤§çº²:
```markdown
# Task Retry ç­–ç•¥æŒ‡å—

## 1. æ¦‚è¿°
- Retry ç­–ç•¥çš„ä½œç”¨
- é€‚ç”¨åœºæ™¯

## 2. é…ç½®æ–¹æ³•
### 2.1 é»˜è®¤é…ç½®
### 2.2 è‡ªå®šä¹‰é…ç½®
### 2.3 é…ç½®å‚æ•°è¯´æ˜

## 3. Retry ç±»å‹
### 3.1 æ— å»¶è¿Ÿ Retry (NONE)
### 3.2 å›ºå®šå»¶è¿Ÿ Retry (FIXED)
### 3.3 çº¿æ€§é€€é¿ Retry (LINEAR)
### 3.4 æŒ‡æ•°é€€é¿ Retry (EXPONENTIAL)

## 4. Retry é™åˆ¶
### 4.1 æœ€å¤§é‡è¯•æ¬¡æ•°
### 4.2 Retry å¾ªç¯æ£€æµ‹
### 4.3 Retry å¤±è´¥å¤„ç†

## 5. æœ€ä½³å®è·µ
### 5.1 ä½•æ—¶ä½¿ç”¨ Retry
### 5.2 Retry æ¬¡æ•°å»ºè®®
### 5.3 Retry å»¶è¿Ÿé…ç½®

## 6. æ•…éšœæ’æŸ¥
### 6.1 Retry æ¬¡æ•°è¶…é™
### 6.2 Retry å¾ªç¯æ£€æµ‹è§¦å‘
### 6.3 Retry å¤±è´¥è¯Šæ–­

## 7. ç›‘æ§å’Œè§‚æµ‹
### 7.1 Retry æ¬¡æ•°ç»Ÿè®¡
### 7.2 Retry æˆåŠŸç‡
### 7.3 Retry å®¡è®¡æ—¥å¿—
```

#### 5.1.2 Timeout é…ç½®æŒ‡å—

**æ–‡ä»¶**: `docs/task/TIMEOUT_CONFIGURATION.md`

å†…å®¹å¤§çº²:
```markdown
# Task Timeout é…ç½®æŒ‡å—

## 1. æ¦‚è¿°
## 2. Timeout é…ç½®
## 3. Timeout æ£€æµ‹
## 4. Timeout å¤„ç†
## 5. æœ€ä½³å®è·µ
## 6. æ•…éšœæ’æŸ¥
## 7. ç›‘æ§å’Œå‘Šè­¦
```

#### 5.1.3 Cancel æ“ä½œæ‰‹å†Œ

**æ–‡ä»¶**: `docs/task/CANCEL_OPERATIONS.md`

å†…å®¹å¤§çº²:
```markdown
# Task Cancel æ“ä½œæ‰‹å†Œ

## 1. æ¦‚è¿°
## 2. Cancel ç±»å‹
### 2.1 Cancel Draft (draft â†’ canceled)
### 2.2 Cancel Approved (approved â†’ canceled)
### 2.3 Cancel Queued (queued â†’ canceled)
### 2.4 Cancel Running (running â†’ canceled)

## 3. Cancel æµç¨‹
## 4. Cleanup æœºåˆ¶
## 5. æœ€ä½³å®è·µ
## 6. æ•…éšœæ’æŸ¥
```

#### 5.1.4 çŠ¶æ€æœºè¿ç»´æ‰‹å†Œ

**æ–‡ä»¶**: `docs/task/STATE_MACHINE_OPERATIONS.md`

å†…å®¹å¤§çº²:
```markdown
# Task çŠ¶æ€æœºè¿ç»´æ‰‹å†Œ

## 1. çŠ¶æ€æœºæ¦‚è§ˆ
### 1.1 çŠ¶æ€å®šä¹‰
### 1.2 è½¬æ¢è§„åˆ™
### 1.3 ç»ˆæ€å¤„ç†

## 2. å¸¸è§æ“ä½œ
### 2.1 åˆ›å»ºä»»åŠ¡
### 2.2 æ‰¹å‡†ä»»åŠ¡
### 2.3 é‡è¯•ä»»åŠ¡
### 2.4 å–æ¶ˆä»»åŠ¡

## 3. é«˜çº§æ§åˆ¶
### 3.1 Retry ç­–ç•¥
### 3.2 Timeout æœºåˆ¶
### 3.3 Cancel å¤„ç†

## 4. ç›‘æ§å’Œè§‚æµ‹
### 4.1 çŠ¶æ€è½¬æ¢å®¡è®¡
### 4.2 ä»»åŠ¡æ‰§è¡ŒæŒ‡æ ‡
### 4.3 å¤±è´¥æ¨¡å¼åˆ†æ

## 5. æ•…éšœæ’æŸ¥
### 5.1 ä»»åŠ¡å¡ä½
### 5.2 çŠ¶æ€ä¸ä¸€è‡´
### 5.3 è½¬æ¢å¤±è´¥

## 6. æ€§èƒ½ä¼˜åŒ–
### 6.1 å¹¶å‘æ§åˆ¶
### 6.2 èµ„æºé™åˆ¶
### 6.3 é˜Ÿåˆ—ç®¡ç†
```

---

## éªŒæ”¶æ ‡å‡†

### æœ€ç»ˆå®Œæˆåº¦ç›®æ ‡: 100%

#### 1. æ ¸å¿ƒä»£ç  (20/20%)

- [x] çŠ¶æ€æœºå®šä¹‰å®Œæ•´
- [x] çŠ¶æ€è½¬æ¢è¡¨å®Œæ•´
- [x] çŠ¶æ€è½¬æ¢æ‰§è¡Œå®Œæ•´
- [ ] Retry ç­–ç•¥é…ç½®å®Œæ•´
- [ ] Retry æ¬¡æ•°é™åˆ¶å®Œæ•´
- [ ] Retry å¾ªç¯æ£€æµ‹å®Œæ•´
- [ ] Timeout é…ç½®å®Œæ•´
- [ ] Timeout æ£€æµ‹å®Œæ•´
- [ ] Timeout å¤„ç†å®Œæ•´
- [ ] Cancel Running å®ç°å®Œæ•´

**éªŒæ”¶æ ‡å‡†**: æ‰€æœ‰æ ¸å¿ƒæ¨¡å—å®ç°å®Œæ•´,ä»£ç å®¡æŸ¥é€šè¿‡

#### 2. æµ‹è¯•è¦†ç›– (20/20%)

- [ ] Retry ç­–ç•¥å•å…ƒæµ‹è¯• (90%+ è¦†ç›–)
- [ ] Timeout å•å…ƒæµ‹è¯• (90%+ è¦†ç›–)
- [ ] Cancel å•å…ƒæµ‹è¯• (90%+ è¦†ç›–)
- [ ] Retry E2E é›†æˆæµ‹è¯• (3+ åœºæ™¯)
- [ ] Timeout E2E é›†æˆæµ‹è¯• (3+ åœºæ™¯)
- [ ] Cancel Running E2E é›†æˆæµ‹è¯• (3+ åœºæ™¯)
- [ ] çŠ¶æ€æœºå®Œæ•´æ€§æµ‹è¯• (æ‰€æœ‰è½¬æ¢è·¯å¾„)

**éªŒæ”¶æ ‡å‡†**: æ‰€æœ‰æµ‹è¯•é€šè¿‡,è¦†ç›–ç‡è¾¾æ ‡

#### 3. æ–‡æ¡£å®Œå–„ (20/20%)

- [ ] Retry ç­–ç•¥æŒ‡å— (3000+ å­—)
- [ ] Timeout é…ç½®æŒ‡å— (2000+ å­—)
- [ ] Cancel æ“ä½œæ‰‹å†Œ (2000+ å­—)
- [ ] çŠ¶æ€æœºè¿ç»´æ‰‹å†Œ (5000+ å­—)
- [ ] API æ–‡æ¡£å®Œæ•´ (æ‰€æœ‰æ–°å¢æ–¹æ³•)

**éªŒæ”¶æ ‡å‡†**: æ–‡æ¡£å®Œæ•´,å¯è¯»æ€§å¼º,ç¤ºä¾‹å……åˆ†

#### 4. é›†æˆéªŒè¯ (20/20%)

- [ ] Retry ç«¯åˆ°ç«¯éªŒè¯é€šè¿‡
- [ ] Timeout ç«¯åˆ°ç«¯éªŒè¯é€šè¿‡
- [ ] Cancel Running ç«¯åˆ°ç«¯éªŒè¯é€šè¿‡
- [ ] ä¸ Supervisor é›†æˆéªŒè¯é€šè¿‡
- [ ] ä¸ Lead Agent é›†æˆéªŒè¯é€šè¿‡

**éªŒæ”¶æ ‡å‡†**: æ‰€æœ‰é›†æˆåœºæ™¯éªŒè¯é€šè¿‡

#### 5. è¿ç»´/è§‚æµ‹ (20/20%)

- [ ] Retry æ¬¡æ•°ç»Ÿè®¡å®Œæ•´
- [ ] Timeout å‘Šè­¦å®Œæ•´
- [ ] Cancel å®¡è®¡æ—¥å¿—å®Œæ•´
- [ ] å¤±è´¥æ¨¡å¼åˆ†æå·¥å…·å®Œæ•´
- [ ] ç›‘æ§æŒ‡æ ‡å®Œæ•´

**éªŒæ”¶æ ‡å‡†**: å¯è§‚æµ‹æ€§å®Œæ•´,æ•…éšœå¯è¯Šæ–­

---

## é£é™©è¯„ä¼°

### ğŸ”´ é«˜é£é™©

1. **å‘åå…¼å®¹æ€§**
   - **é£é™©**: ä¿®æ”¹ Task æ¨¡å‹å¯èƒ½å½±å“ç°æœ‰ä»£ç 
   - **ç¼“è§£**: æ‰€æœ‰æ–°å­—æ®µéƒ½åœ¨ metadata ä¸­,ä¸å½±å“ç°æœ‰å­—æ®µ
   - **å›æ»š**: ä¿ç•™åŸæœ‰ API,æ–°å¢æ–¹æ³•ä¸å½±å“æ—§ä»£ç 

2. **å¹¶å‘å®‰å…¨**
   - **é£é™©**: Retry/Timeout/Cancel å¯èƒ½äº§ç”Ÿç«æ€æ¡ä»¶
   - **ç¼“è§£**: ä½¿ç”¨ SQLiteWriter ä¸²è¡ŒåŒ–å†™æ“ä½œ
   - **æµ‹è¯•**: å¹¶å‘å‹æµ‹éªŒè¯

### ğŸŸ¡ ä¸­é£é™©

1. **æ€§èƒ½å½±å“**
   - **é£é™©**: Timeout æ£€æµ‹å¢åŠ è¿è¡Œæ—¶å¼€é”€
   - **ç¼“è§£**: åªåœ¨æ¯æ¬¡è¿­ä»£æ£€æµ‹ä¸€æ¬¡,å¼€é”€å¯æ§
   - **æµ‹è¯•**: æ€§èƒ½åŸºå‡†æµ‹è¯•

2. **çŠ¶æ€ä¸ä¸€è‡´**
   - **é£é™©**: Runner crash å¯èƒ½å¯¼è‡´çŠ¶æ€ä¸ä¸€è‡´
   - **ç¼“è§£**: ä½¿ç”¨ Recovery æœºåˆ¶æ¢å¤çŠ¶æ€
   - **æµ‹è¯•**: Chaos æµ‹è¯•éªŒè¯

### ğŸŸ¢ ä½é£é™©

1. **æ–‡æ¡£è¿‡æ—¶**
   - **é£é™©**: ä»£ç æ›´æ–°åæ–‡æ¡£æœªåŒæ­¥
   - **ç¼“è§£**: ä»£ç å’Œæ–‡æ¡£åŒæ­¥å®¡æŸ¥
   - **æµç¨‹**: åˆå¹¶å‰å¿…é¡»æ›´æ–°æ–‡æ¡£

---

## å®æ–½æ—¶é—´è¡¨

| Phase | ä»»åŠ¡ | å·¥æœŸ | ä¾èµ– | è´Ÿè´£äºº | å¼€å§‹æ—¥æœŸ | ç»“æŸæ—¥æœŸ |
|-------|------|------|------|--------|---------|---------|
| 1 | Retry ç­–ç•¥ç³»ç»Ÿ | 3å¤© | - | [å¾…å®š] | Day 1 | Day 3 |
| 2 | Timeout æœºåˆ¶ | 2å¤© | Phase 1 | [å¾…å®š] | Day 4 | Day 5 |
| 3 | Cancel è¿è¡Œä»»åŠ¡ | 2å¤© | Phase 2 | [å¾…å®š] | Day 6 | Day 7 |
| 4 | æµ‹è¯•å®Œå–„ | 2å¤© | Phase 1-3 | [å¾…å®š] | Day 8 | Day 9 |
| 5 | æ–‡æ¡£å®Œå–„ | 1å¤© | Phase 1-4 | [å¾…å®š] | Day 10 | Day 10 |

**æ€»å·¥æœŸ**: 10 å·¥ä½œæ—¥ (çº¦ 2 å‘¨)

---

## äº¤ä»˜æ¸…å•

### ä»£ç äº¤ä»˜

- [ ] `agentos/core/task/retry_strategy.py` (æ–°å¢)
- [ ] `agentos/core/task/timeout_manager.py` (æ–°å¢)
- [ ] `agentos/core/task/cancel_handler.py` (æ–°å¢)
- [ ] `agentos/core/task/models.py` (ä¿®æ”¹)
- [ ] `agentos/core/task/service.py` (ä¿®æ”¹)
- [ ] `agentos/core/runner/task_runner.py` (ä¿®æ”¹)

### æµ‹è¯•äº¤ä»˜

- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•æ–‡ä»¶ (6ä¸ª)
- [ ] æ‰€æœ‰é›†æˆæµ‹è¯•æ–‡ä»¶ (3ä¸ª)
- [ ] æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š (90%+)

### æ–‡æ¡£äº¤ä»˜

- [ ] RETRY_STRATEGY_GUIDE.md
- [ ] TIMEOUT_CONFIGURATION.md
- [ ] CANCEL_OPERATIONS.md
- [ ] STATE_MACHINE_OPERATIONS.md
- [ ] API æ–‡æ¡£æ›´æ–°

### éªŒæ”¶äº¤ä»˜

- [ ] éªŒæ”¶æµ‹è¯•æŠ¥å‘Š
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š
- [ ] å…¼å®¹æ€§æµ‹è¯•æŠ¥å‘Š
- [ ] æœ€ç»ˆå®Œæˆåº¦è¯„ä¼°æŠ¥å‘Š (100%)

---

## åç»­æ”¹è¿› (æœªæ¥è¿­ä»£)

1. **æ™ºèƒ½ Retry ç­–ç•¥** (åŸºäºé”™è¯¯ç±»å‹è‡ªåŠ¨é€‰æ‹© backoff)
2. **åŠ¨æ€ Timeout è°ƒæ•´** (åŸºäºå†å²æ‰§è¡Œæ—¶é—´è‡ªåŠ¨è°ƒæ•´)
3. **Cancel ä¼˜å…ˆçº§** (é«˜ä¼˜å…ˆçº§ cancel ä¼˜å…ˆå¤„ç†)
4. **Retry æ¨¡å¼åˆ†æ** (æœºå™¨å­¦ä¹ é¢„æµ‹ retry æˆåŠŸç‡)
5. **Timeout é¢„æµ‹** (æå‰é¢„è­¦å¯èƒ½è¶…æ—¶çš„ä»»åŠ¡)

---

## è”ç³»æ–¹å¼

**é¡¹ç›®è´Ÿè´£äºº**: [å¾…å®š]
**æŠ€æœ¯æ”¯æŒ**: [å¾…å®š]
**æ–‡æ¡£ç»´æŠ¤**: [å¾…å®š]

---

**æœ€åæ›´æ–°**: 2026-01-29
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: å¾…å®¡æ‰¹
